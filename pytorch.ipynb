{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "a2apqwaq011s",
        "Q8PS2VwTGIK3",
        "KwkXnQytIWEQ",
        "ELF6i6-Ms6FN",
        "XtzjeDop_uZt",
        "QGlap62a8gl2",
        "7ZwnXi7Go-VK",
        "PT0Phxhs99Q2",
        "JHsQhXNL2wvN"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "43e4739fabb447c3a3b685e2e6c50d46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5d0fdf9c002a45049bb5f22114613395",
              "IPY_MODEL_f84e78d925ca41a49c29f524e7a0d71d",
              "IPY_MODEL_266ba5dd12b5444c9d9357d8cf4354b5"
            ],
            "layout": "IPY_MODEL_21af79cb3ac1425592462a56261777e0"
          }
        },
        "5d0fdf9c002a45049bb5f22114613395": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d9bf1bdc3cd475fb759dfc0d65b119c",
            "placeholder": "​",
            "style": "IPY_MODEL_0044c573ce814f9dae0d26e70ee721f7",
            "value": "100%"
          }
        },
        "f84e78d925ca41a49c29f524e7a0d71d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2eaaa6e826d4d858198fa45c4a83fc4",
            "max": 26421880,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_55ad2026281d4a4aad7d29e3c204ba4b",
            "value": 26421880
          }
        },
        "266ba5dd12b5444c9d9357d8cf4354b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_13e1bb50d3b74650a46b91b12da8f467",
            "placeholder": "​",
            "style": "IPY_MODEL_9abfe2382c5c41c9bdf3e8c766fdde27",
            "value": " 26421880/26421880 [00:01&lt;00:00, 27208597.53it/s]"
          }
        },
        "21af79cb3ac1425592462a56261777e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d9bf1bdc3cd475fb759dfc0d65b119c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0044c573ce814f9dae0d26e70ee721f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d2eaaa6e826d4d858198fa45c4a83fc4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55ad2026281d4a4aad7d29e3c204ba4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "13e1bb50d3b74650a46b91b12da8f467": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9abfe2382c5c41c9bdf3e8c766fdde27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b7f5144837884439aa79ae9066c9d594": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3a446c89fa4343e1a50edba66f1cca19",
              "IPY_MODEL_44dab35374934840a1082587a77563f8",
              "IPY_MODEL_c645236658a34465bf1fe2323c66c33e"
            ],
            "layout": "IPY_MODEL_42e835125ce34f958291e3d0abc72c91"
          }
        },
        "3a446c89fa4343e1a50edba66f1cca19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_46927d896d1646cda426e33ea2eb2069",
            "placeholder": "​",
            "style": "IPY_MODEL_679005bd1ace42b7b5cf5551f7441eda",
            "value": "100%"
          }
        },
        "44dab35374934840a1082587a77563f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7dddd17eff443389077542d70170d47",
            "max": 29515,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_311e78e9a1fa465c8b40b477f14038de",
            "value": 29515
          }
        },
        "c645236658a34465bf1fe2323c66c33e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba721330e99f4facabba27b7e69e9637",
            "placeholder": "​",
            "style": "IPY_MODEL_da5b46638f3d450fb7c7085f9cf51012",
            "value": " 29515/29515 [00:00&lt;00:00, 298035.92it/s]"
          }
        },
        "42e835125ce34f958291e3d0abc72c91": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46927d896d1646cda426e33ea2eb2069": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "679005bd1ace42b7b5cf5551f7441eda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c7dddd17eff443389077542d70170d47": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "311e78e9a1fa465c8b40b477f14038de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ba721330e99f4facabba27b7e69e9637": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da5b46638f3d450fb7c7085f9cf51012": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "919d17356dd249bd8328b26f6394bead": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5a9b034b36bb4c1da9f5c30e9d7ba340",
              "IPY_MODEL_cd5a723f5ba443b69f37b218bbc7cd36",
              "IPY_MODEL_74dcba7430084d42b7f15a429c1917d8"
            ],
            "layout": "IPY_MODEL_184021ea850a464f9a61f68c4efc732f"
          }
        },
        "5a9b034b36bb4c1da9f5c30e9d7ba340": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_adc8f53d45784fa595b32098a2b3300b",
            "placeholder": "​",
            "style": "IPY_MODEL_341d4e4e42a44160b14b50d3f5ad16da",
            "value": "100%"
          }
        },
        "cd5a723f5ba443b69f37b218bbc7cd36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_71deebae3d844a83877a16d20699cf5b",
            "max": 4422102,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0bedf18baa554d378f4d2628f642a96b",
            "value": 4422102
          }
        },
        "74dcba7430084d42b7f15a429c1917d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad35a8e43a23434b9e2d6dcfa257b161",
            "placeholder": "​",
            "style": "IPY_MODEL_5f106fa4b06c476da6a62b13bb63298f",
            "value": " 4422102/4422102 [00:00&lt;00:00, 8597554.34it/s]"
          }
        },
        "184021ea850a464f9a61f68c4efc732f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "adc8f53d45784fa595b32098a2b3300b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "341d4e4e42a44160b14b50d3f5ad16da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "71deebae3d844a83877a16d20699cf5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0bedf18baa554d378f4d2628f642a96b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ad35a8e43a23434b9e2d6dcfa257b161": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f106fa4b06c476da6a62b13bb63298f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "70ad99869fc443de9a1123598e198a1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8b1c496cc419445aa20232f75022b561",
              "IPY_MODEL_64b6ee96232b45b390e5d01ddd8e2452",
              "IPY_MODEL_df7eff329ac846b5ad1dde7c1e536501"
            ],
            "layout": "IPY_MODEL_55e5fea1146545708f939603fadd8e39"
          }
        },
        "8b1c496cc419445aa20232f75022b561": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b3be6f4adc61425fb12dae530d1c7c37",
            "placeholder": "​",
            "style": "IPY_MODEL_ee36db3326b54af4a383803dc631270b",
            "value": "100%"
          }
        },
        "64b6ee96232b45b390e5d01ddd8e2452": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2040ebc6235949f79a76a724ad0acbc4",
            "max": 5148,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ddd93a1fb6504e228938d0596f1d7935",
            "value": 5148
          }
        },
        "df7eff329ac846b5ad1dde7c1e536501": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_306b6a0bee9b4dd8b3e307d18e66e2b6",
            "placeholder": "​",
            "style": "IPY_MODEL_feb841444fdd4aa6961b4d344edfd531",
            "value": " 5148/5148 [00:00&lt;00:00, 62391.00it/s]"
          }
        },
        "55e5fea1146545708f939603fadd8e39": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3be6f4adc61425fb12dae530d1c7c37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee36db3326b54af4a383803dc631270b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2040ebc6235949f79a76a724ad0acbc4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ddd93a1fb6504e228938d0596f1d7935": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "306b6a0bee9b4dd8b3e307d18e66e2b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "feb841444fdd4aa6961b4d344edfd531": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#Dependencies\n",
        "import torch\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "ntjRF5dhp4nO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Tensor basics**"
      ],
      "metadata": {
        "id": "a2apqwaq011s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#In pytorch, everything is based on tensor operations\n",
        "#From numpy we know arrays and vectors, and now in pytorch everything is a tensor\n",
        "#A tensor can have differentd dimensions: So it can be 1D, 2D, 3D...\n"
      ],
      "metadata": {
        "id": "MCLqr_PWmn4w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=torch.empty(1) #x is a tensor with size=1"
      ],
      "metadata": {
        "id": "l6RpwMCGo2s4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x) #It prints an empty tensor; The value is not initilized yet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "olG0Sv9fpaLN",
        "outputId": "dc4af849-68e6-4335-dd29-a7876dbd1e89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2.7186e-35])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x1=torch.empty(3) # This is like a 1D vector with 3 elements."
      ],
      "metadata": {
        "id": "WzFGbbY9ph0r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x2=torch.empty(2,3) #This is like a 2D matrix ..."
      ],
      "metadata": {
        "id": "0Wys4HGaprMq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wuBBTkrUuAN8",
        "outputId": "87ee6e76-cb8f-44db-d0cc-cf122dd7b9e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[7.7836e-35, 0.0000e+00, 3.3631e-44],\n",
            "        [0.0000e+00,        nan, 0.0000e+00]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x3=torch.empty(2,3,3) #3D\n",
        "print(x3)"
      ],
      "metadata": {
        "id": "EYY42b9rpzfz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a297ae60-3f82-420f-81a0-b5887a7a219c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[2.4567e-35, 0.0000e+00, 0.0000e+00],\n",
            "         [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "         [0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
            "\n",
            "        [[0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "         [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "         [0.0000e+00, 0.0000e+00, 0.0000e+00]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=torch.rand(2,2) #create a tensor with random values."
      ],
      "metadata": {
        "id": "RKnM54ySp9QZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x0=torch.zeros(2,2)\n",
        "x1=torch.ones(2,2)"
      ],
      "metadata": {
        "id": "lJRFgl1fqIor"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x.dtype) #It is by default torch.float32  \n",
        "#We can also give it the dtype parameter\n",
        "#For instance:\n",
        "x=torch.empty(2,2,dtype=torch.int)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWS4KsywqPPA",
        "outputId": "a09e2662-d0ea-475d-922b-df611459c129"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x.size()) #In order to print the size/ size is a function, so we have to put parenthesis"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PzX1aIN0q00t",
        "outputId": "a9aa0dd7-ee95-4e95-ce11-116f0f6caddf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#We can also create a tensor for data, for example for a python list\n",
        "L=[2,3]\n",
        "x=torch.tensor(L)\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZEbU2qKrOWa",
        "outputId": "0720bd64-bfa7-4c0b-de3c-4abe1f1ffe19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y1=torch.rand(2,2)\n",
        "y2=torch.rand(2,2)\n",
        "y=y1+y2 #or y=torch.add(x,y)\n",
        "y1.add_(x) #Modify y and add all of the elements of x to our y  #And by the way, in pytorch, every function that has a trailing underscore (_) will do an inplace operation\n",
        "y=y1-y2 #or y=torch.sub(x,y)\n",
        "y=y1*y2 #or y=torch.mul(x,y) \n",
        "y=y1/y2 #or y=torch.div(x,y)\n",
        "#and again we can do everything inplace by using the (_)\n"
      ],
      "metadata": {
        "id": "4zXXhhJFrvaq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Slicing\n",
        "x=torch.rand(5,3)\n",
        "print(\"x=\",x)\n",
        "print(\"slicing:\",x[:,0])\n",
        "print(\"tensor with 1 element: \", x[1,1])\n",
        "print(\"with item method\", x[1,1].item()) #You can use this only when you have one element in your tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tp1Xm9ZWyH4-",
        "outputId": "723f050f-3093-472f-ba51-977030da469f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x= tensor([[0.9544, 0.4223, 0.3329],\n",
            "        [0.7394, 0.3166, 0.6702],\n",
            "        [0.2047, 0.4028, 0.8621],\n",
            "        [0.3796, 0.6737, 0.0462],\n",
            "        [0.1625, 0.0374, 0.6549]])\n",
            "slicing: tensor([0.9544, 0.7394, 0.2047, 0.3796, 0.1625])\n",
            "tensor with 1 element:  tensor(0.3166)\n",
            "with item method 0.3166089653968811\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Reshaping\n",
        "x=torch.rand(4,4)\n",
        "print(\"x=\",x)\n",
        "y=x.view(16) #Of course the number of elements must still the same.\n",
        "print(\"y=\",y)\n",
        "z=x.view(-1,8)  #If we don't want to put the value in one dimension, and only specify the other dimension: So here it must be 2 by 8\n",
        "print(\"z=\",z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-pdFngQ0r2M",
        "outputId": "f65b1325-eaff-4194-c440-5a3766093a9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x= tensor([[0.1677, 0.8821, 0.7469, 0.0177],\n",
            "        [0.7378, 0.7133, 0.8538, 0.4459],\n",
            "        [0.8474, 0.1801, 0.3907, 0.9194],\n",
            "        [0.0306, 0.7960, 0.7817, 0.7466]])\n",
            "y= tensor([0.1677, 0.8821, 0.7469, 0.0177, 0.7378, 0.7133, 0.8538, 0.4459, 0.8474,\n",
            "        0.1801, 0.3907, 0.9194, 0.0306, 0.7960, 0.7817, 0.7466])\n",
            "z= tensor([[0.1677, 0.8821, 0.7469, 0.0177, 0.7378, 0.7133, 0.8538, 0.4459],\n",
            "        [0.8474, 0.1801, 0.3907, 0.9194, 0.0306, 0.7960, 0.7817, 0.7466]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Tensor to numpy\n",
        "a=torch.ones(5)\n",
        "b=a.numpy()\n",
        "print(\"a=\",a)\n",
        "print(\"Type of a: \",type(a)) #Be careful type(a) and not a.dtype, otherwise you will get the type of the elements, or let's say Data type, (which is torch.float32 in this case).\n",
        "print(\"b=\",b)\n",
        "print(\"Type of b: \",type(b)) #Be careful type(b) and not b.dtype, otherwise you will get the type of the elements(which is float32 in this case).\n",
        "#Now we have to take care; If the tensor is in the CPU and not the GPU, with this writing, a and by share the same memory location; So if you change one, the other will change\n",
        "\n",
        "by=np.zeros(5)\n",
        "a=torch.from_numpy(by)\n",
        "print(a)\n",
        "\n",
        "#Numpy to tensor\n",
        "b=np.ones(5)\n",
        "a=torch.from_numpy(b)\n",
        "print(\"a=\",a)\n",
        "print(\"b=\",b)\n",
        "b+=1\n",
        "print(\"a=\",a)\n",
        "print(\"b=\",b) #This only happens when we are working with the CPU.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fwy-_B40S7T",
        "outputId": "6c791792-3c71-47ad-e4cc-e13adb40411e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a= tensor([1., 1., 1., 1., 1.])\n",
            "Type of a:  <class 'torch.Tensor'>\n",
            "b= [1. 1. 1. 1. 1.]\n",
            "Type of b:  <class 'numpy.ndarray'>\n",
            "a= tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n",
            "b= [1. 1. 1. 1. 1.]\n",
            "a= tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n",
            "b= [2. 2. 2. 2. 2.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "  print(\"True\")\n",
        "else:\n",
        "  print(\"False\")"
      ],
      "metadata": {
        "id": "NRMErqbfvdPy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1296e142-f393-4104-92ff-7c60cf052a0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srLV77dgvk2c",
        "outputId": "c55b2772-2138-4019-c710-865398c326c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Nov 28 08:43:56 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   31C    P8     9W /  70W |      3MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#How to check if cuda toolkit is available:\n",
        "if torch.cuda.is_available():\n",
        "  print(\"Cuda is available\")\n",
        "  device=torch.device(\"cuda\")\n",
        "  #And then if you want to create a tensor on the gpu, you can do this by saying:\n",
        "  x=torch.ones(5,device=device) #This will create  a tesor and put it on the GPU\n",
        "  #or we can from first create it so simply by:\n",
        "  x=torch.ones(5)\n",
        "  #And then move it to your device(to your gpu) by:\n",
        "  y=y.to(device)\n",
        "  #And then:\n",
        "  z=x+y #This will be performed in the GPU, and it might be much faster.\n",
        "  #But be carefull: If we do z.numpy() it will return an error because numpy can only handle cpu tensors, so you have to move it back to cpu, and then transform it to numpy,\n",
        "  #and that is by doing z=z.to(\"cpu\")\n",
        "  "
      ],
      "metadata": {
        "id": "GFshmKW_7iLW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Remark: A lot of times when you define  tensor, you will observe a  \"requires_grad\" thing: \n",
        "x=torch.ones(5,requires_grad=True) #This will tell pytorch that it will need to calculate the gradients for this tensor later in your optimization steps.\n",
        "#So, whenever you have a variable in your model that you want to optimize, then you need the gradients so you need to specify requires_grad equals to True.\n"
      ],
      "metadata": {
        "id": "Vjm43K4xCqUK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Autograd: Gradient computing**"
      ],
      "metadata": {
        "id": "Q8PS2VwTGIK3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Gradiants are essential for our model optimization --> fortunately, pytorch provides the autograd package; which can do all the computations for us.\n",
        "\n",
        "x=torch.randn(3) #randn gives a real number between -1 to 1. Mathematically, randn gives a number from Normal Distribution, whereas, rand gives a number from Uniform Distribution.\n",
        "#######Now, let's say later we want to calculate the gradients of some functions with respect to x, then what we have to do is we must specify the argument requires_grad=True  :\n",
        "x=torch.randn(3,requires_grad=True)\n",
        "print(\"x=\",x)\n",
        "#######Whenever we do operations with this tensor, pytorch will create a so-called computational graph for us\n",
        "y=x+2 #This will create the computational graph \n",
        "#x--(+)-->y\n",
        "#2/\n",
        "\n",
        "#First we do a forward pass; so here we apply the operation y=x+2, in the forward pass we calculate the output y; and since we specified that it requiers the gradient, pytorch will then automatically create\n",
        "#and store a function for us[called Add Backward], and this function is then used in the backpropagation and to get the gradients: So here, y has an attribute grad_fn: This will point to a gradient function\n",
        "#and in this case it is called Add Backward, and with this function we can then calculate the gradients in the so-called backward pass. So this will calculate the gradient of y with respect to x in this case(dy/dx).\n",
        "#print(y): look for the result of this to understand more.\n",
        "print(\"y=\",y)\n",
        "#z=y*y*2\n",
        "#z=z.mean()\n",
        "#print(\"z=\",z)\n",
        "#z.backward()\n",
        "#print(\"x.grad=\",x.grad)\n",
        "\n",
        "#But y is not a scalar, so if we do y.backward() it will prompts this error: grad can be implicitly created only for scalar outputs.\n",
        "#So, in this case we have to give it the gradient argument; So we have to create a vector of the same size.\n",
        "v=torch.tensor([.1,1.0,0.001],dtype=torch.float32)\n",
        "#and then we must pass this vector to our backward function\n",
        "y.backward(v)\n",
        "print(\"x.grad\",x.grad) #dz/dx\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WYfZohYVGOAW",
        "outputId": "36908933-72ac-4484-89f8-7c7c6e50af21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x= tensor([ 1.3473, -1.7253, -1.0084], requires_grad=True)\n",
            "y= tensor([3.3473, 0.2747, 0.9916], grad_fn=<AddBackward0>)\n",
            "x.grad tensor([0.1000, 1.0000, 0.0010])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Also some other thing that we should know is how we can prevent pytorch from tracking the history and calculating the grad_fn attribute. So for example sometimes during our training loop,\n",
        "#when we want to update our weights then this operation should not be part of the gradient computation.\n",
        "#For now we are going to know how to prevent the torch.randn(3,requires_grad=True) from tracking the gradients, and we have 3 options for this.\n",
        "#1) x.requires_grad_(False)\n",
        "#2) x.detach : This will create a new tensor that doesn't require the gradient expl: y=x.detach()\n",
        "#3)with torch.no_grad(): and then we can do our operations.\n",
        "x=torch.randn(3,requires_grad=True)\n",
        "print(x)\n",
        "x.requires_grad_(False)  ####And as we have said earlier, whenever a fuction has a trailing underscore in pytorch, then this means that it will modify our variable inplace:\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fTshfWn37i1e",
        "outputId": "4b4e13cb-4c97-4ca1-8f96-f168541ed70f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 1.1179, -0.6114, -0.8053], requires_grad=True)\n",
            "tensor([ 1.1179, -0.6114, -0.8053])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=torch.randn(3,requires_grad=True)\n",
        "with torch.no_grad():\n",
        "  y=x+2\n",
        "  print(\"x=\",x)\n",
        "  print(\"y=\",y)\n",
        "#otherwise y will has the gradient function"
      ],
      "metadata": {
        "id": "_1asAm0t72Xv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f90ab891-f010-479d-8d5c-757dbacb09d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x= tensor([-2.2029, -0.0075,  0.4953], requires_grad=True)\n",
            "y= tensor([-0.2029,  1.9925,  2.4953])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#So these are the three ways how we can stop pytorch from creating this gradient functions and tracking the history in our computational graph.\n",
        "#!!One more very important thing is that what we should also know is whenever we call the backward function, then the gradient for this tensor will be accumulated into the .grad attribute : The values will be\n",
        "#summed up"
      ],
      "metadata": {
        "id": "dxqPA1oq-jiu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Let's deal with a dummy example which simulates some model output\n",
        "weights = torch.ones(4,requires_grad=True)\n",
        "print(f'weights= {weights}')\n",
        "#Training loop\n",
        "for epoch in range(1):\n",
        "  model_output = (weights*3).sum()\n",
        "\n",
        "  model_output.backward() #To calculate the gradients\n",
        "#And now we have the gradient, so when we call weights.grad:\n",
        "  print(f'weights.grad\"={weights.grad}') #Which is the derivative of model_output/weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJMw6WLYBfnZ",
        "outputId": "af395a07-cbe4-4d65-f925-05de24e174bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "weights= tensor([1., 1., 1., 1.], requires_grad=True)\n",
            "weights.grad\"=tensor([3., 3., 3., 3.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#And now if we do another iteration; if we say we have 2 iterations, then the second backward call will again accumulate the values and write them into the grad attribute\n",
        "weights = torch.ones(4,requires_grad=True)\n",
        "for epoch in range(2):\n",
        "  model_output = (weights*3).sum()\n",
        "\n",
        "  model_output.backward() #To calculate the gradients\n",
        "  print(weights.grad)\n",
        "  weights.grad.zero_() #Our gradients are correct again"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqCBKMjmGnlw",
        "outputId": "7220b622-4da7-446b-d57c-f98bbeec73f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3., 3., 3., 3.])\n",
            "tensor([3., 3., 3., 3.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weights = torch.ones(4,requires_grad=True)\n",
        "optimizer=torch.optim.SGD(weights,lr=0.01)\n",
        "optimizer.step()\n",
        "optimizer.zero_grad()\n",
        "####For now, the thing you should remember is that whanever we want to calculate the gradients, we must specify the requires_grad parameter and set it to true, then we can simply calculate the gradients\n",
        "#with .backward() function ,and before we want to do the next operation, or the next iteration in our optimization steps, we must empty our gradient: using the weights.grad.zero() function, and we also\n",
        "#should know how we can prevent some operations from being tracked in the computational graph."
      ],
      "metadata": {
        "id": "y8A7z8JnHNSf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Backpropagation** "
      ],
      "metadata": {
        "id": "KwkXnQytIWEQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Look for the illustration in the notebook :)"
      ],
      "metadata": {
        "id": "e18kd3DVIZxL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#For every operation we do with our tensor, pytorch will create a graph for us: So, where at each node we apply one operation or one function with some inputs and then get an output. \n",
        "#For example :    x\\  \n",
        "#                   (*)-->z        : z=x*y : Here in this case, we use a multiplication operation: And now at these nodes, we can calculate so-called local gradients and we can use them later at the chain rule\n",
        "#                 y/                         to get the final gradient:  Here in this case:  dz/dx= dxy/dx=y and dz/dy= dxy/y=x here we have two local gradients.\n",
        "#                                            -Why do we need them? because typically our graph has more operations and at the very end we calculate a loss function that we want to minimze. So we have to \n",
        "#                                             calculate the gradient of this loss with respect to our parameter x in the beginning."
      ],
      "metadata": {
        "id": "t47t0gokWsq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#The hole concept consists of three steps: 1)Forward pass: compute loss\n",
        "#                                          2)Compute \"local\" gradients\n",
        "#                                          3)Backward pass: Compute dLoss/ dWeights using the Chain rule\n",
        "#==>> Loss, then local gradients , and then dLoss/dWeights"
      ],
      "metadata": {
        "id": "ZQyK5s0iaa3Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Now we will be looking at a concrete example:                                                                                                  x\\\n",
        "#Here we want to use linear regression: basically we model our output with a linear combination of some weights and an input, so our ŷ=wx .        (*)-->ŷ--(-)-->s--(²)-->Loss\n",
        "#and for the loss: Loss=(ŷ-y)²=(wx-y)², Well it should be the MSE, but for simplicity, we just use the sqaurred error                           w/        y/\n",
        "#And now we want to minimize our loss: we want to know the derivative of the loss with respect to our weighs: After dealing with the forward pass, it comes the part of computing the local gradients: dloss/ds,\n",
        "#ds/dŷ, dŷ/dx and dŷ/dw.\n",
        "#And then we do a backward pass: dloss/ds, then dloss/dŷ, and finally dloss/dw (using the chain rule)\n",
        "#We can find an example in the notebook (where we've chosen to work with the case where we have at the beginnig x=1, w=1 and y=2 )\n",
        "#In the example we have found dloss/dw=-2. Let's see now here:"
      ],
      "metadata": {
        "id": "02IBThJMcRr1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "E7B4OOyd43vd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor(1.0)\n",
        "y=torch.tensor(2.0)\n",
        "\n",
        "w=torch.tensor(1.0,requires_grad=True)\n",
        "print(\"The first weight equals= \",w.item())\n",
        "#forward pass and compute the loss\n",
        "y_hat=w*x\n",
        "print(f'y_hat= {y_hat}')\n",
        "loss=(y_hat-y)**2\n",
        "print(\"The loss equals: \",loss.item())\n",
        "#Backward pass : Pytorch will compute the local gradients automatically for us, and also computes the backward pass automatically for us. So the only thing that we have to call is:\n",
        "loss.backward() #This is the hole gradient computation\n",
        "print(\"The first gradient after the first forward and backward pass= \",w.grad.item()) #This is the first gradient after the first forward and backward pass.\n",
        "#And the next steps should be: *Update weights\n",
        "#                              *Next forward and backward pass.... And do this for a couple of iterations.. And that's how backpropagation works\n"
      ],
      "metadata": {
        "id": "VEhofti7gfJo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4494bcb8-8559-4821-9e44-0d8ba1d5c1c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The first weight equals=  1.0\n",
            "y_hat= 1.0\n",
            "The loss equals:  1.0\n",
            "The first gradient after the first forward and backward pass=  -2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Gradient descent using Autograd**"
      ],
      "metadata": {
        "id": "gqA17Mg7-AV0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#In this part, we will be dealing with a concrete example on how to optimize our model with automatic gradient computation using the pytorch autograd package.\n",
        "#So we start by implementing the linear regression algorithm from scratch where we do every step  manually; So we implement the equations to calculate the model prediction and the loss function,\n",
        "#then we do a numerical computation of the gradients and implement the formula, and then we implement the gradient descent algorithm to optimize our parameters. When this is working, we see how we can replace\n",
        "#the manually computed gradients with the automatic back propagation algorithm from pytorch, and in the third step we replace the manually computed loss and parameter updates by using the loss and optimize\n",
        "#classes in pytorch, and in the final step, we replace the manually computed model prediction by implementing a  pytorch model. So when we understand most of these steps, pytorch can do most of  the work for us;\n",
        "#Of course we still have to design our model and have to know which loss and optimizer we should use, but we don't have to worry about the underlying algorithms anymore:\n",
        "\n",
        "\"\"\"1: Prediction: Manually\n",
        "      Gradients computation: Manually\n",
        "      Loss computation: Manually\n",
        "      Parameter updates: Manually\n",
        "    \n",
        "    2:Prediction: Manually\n",
        "      Gradients computation: Autograd\n",
        "      Loss computation: Manually\n",
        "      Parameter updates: Manually\n",
        "\n",
        "    3:Prediction: Manually\n",
        "      Gradients computation: Autograd\n",
        "      Loss computation: Pytorch loss\n",
        "      Parameter updates: Pytorch optimizer\n",
        "\n",
        "    4:Prediction: Pytorch model\n",
        "      Gradients computation: Autograd\n",
        "      Loss computation: Pytorch loss\n",
        "      Parameter updates: Pytorch optimizer \"\"\""
      ],
      "metadata": {
        "id": "QaFbsTdz-ivP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch"
      ],
      "metadata": {
        "id": "q4IMNOoB-4vB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#We will be using a linear regression; so we use a fuction which just does a linear combination of some weights: f=wx (we don't care about the bias here)\n",
        "#Let's say f= 2*x\n",
        "#And then let's do some training samples. So let's say:\n",
        "X=np.array([1,2,3,4],dtype=np.float32)\n",
        "Y=np.array([2,4,6,8],dtype=np.float32)\n",
        "#And now we initialize our weights:\n",
        "w=0.0#After training, this should be equal to 2.0\n",
        "#And now we have to calculate our model prediction, the loss, and the gradients; And we will be doing this manually for the fist time.\n",
        "\n",
        "#Model prediction\n",
        "def forward(x):\n",
        "  return w*x\n",
        "\n",
        "#Loss: MSE\n",
        "def loss(y,y_hat):\n",
        "  return ((y_hat-y)**2).mean()\n",
        "\n",
        "#Gradient\n",
        "#Now we have to calculate the gradient of the loss with respect to our parameters.\n",
        "#MSE=1/N*(w*x-y)²\n",
        "#Its derivative is: dJ/dw= 1/N * 2 * x *(w*x-y) :So this is the numerical computed derivative.\n",
        "def gradient(x,y,y_hat):\n",
        "  return np.dot(2*x,y_hat-y).mean()\n",
        "\n",
        "\n",
        "\n",
        "#Now let's print our prediction before the training\n",
        "print(f'Prediction before training f(5)={forward(5):.3f}')\n",
        "\n",
        "#Training\n",
        "learning_rate= 0.01\n",
        "n_iters=11\n",
        "\n",
        "for epoch in range(n_iters):\n",
        "\n",
        "  #prediction=forward pass\n",
        "  y_pred=forward(X)\n",
        "\n",
        "  #Loss\n",
        "  l=loss(Y,y_pred)  \n",
        "\n",
        "  #Gradients\n",
        "  dw=gradient(X,Y,y_pred)\n",
        "\n",
        "  #update weights (using the gradient descent algorithm)\n",
        "  w-=learning_rate* dw\n",
        "\n",
        "  if epoch % 1==0: #Why %1? Because here we want for every step.\n",
        "    print(f'epoch:<{epoch+1}: w= {w:.3f}, loss={l:8f}')\n",
        "    \n",
        "print(f'Prediction After training training f(5)={forward(5):.3f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gVo3ub3TChTT",
        "outputId": "2049380d-a3ba-493e-df53-ece87de569ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction before training f(5)=0.000\n",
            "epoch:<1: w= 1.200, loss=30.000000\n",
            "epoch:<2: w= 1.680, loss=4.799999\n",
            "epoch:<3: w= 1.872, loss=0.768000\n",
            "epoch:<4: w= 1.949, loss=0.122880\n",
            "epoch:<5: w= 1.980, loss=0.019661\n",
            "epoch:<6: w= 1.992, loss=0.003146\n",
            "epoch:<7: w= 1.997, loss=0.000503\n",
            "epoch:<8: w= 1.999, loss=0.000081\n",
            "epoch:<9: w= 1.999, loss=0.000013\n",
            "epoch:<10: w= 2.000, loss=0.000002\n",
            "epoch:<11: w= 2.000, loss=0.000000\n",
            "Prediction After training training f(5)=10.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Well in the precedent work, the implementation have been done manually; and now let's replace the gradient calculation"
      ],
      "metadata": {
        "id": "Az-oPG3Eb9_j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#We will be using a linear regression; so we use a fuction which just does a linear combination of some weights: f=wx (we don't care about the bias here)\n",
        "#Let's say f= 2*x\n",
        "#And then let's do some training samples. So let's say:\n",
        "\n",
        "\n",
        "\n",
        "'''#################\"X, Y, and w should all be tensors.#################'''\n",
        "X=torch.tensor([1,2,3,4],dtype=torch.float32)\n",
        "Y=torch.tensor([2,4,6,8],dtype=torch.float32)\n",
        "#And now we initialize our weights:\n",
        "w=torch.tensor(0.0,dtype=torch.float32,requires_grad=True)\n",
        "#We added requires_grad=True in the w argument since we are interested in the gradient of our loss with respect to this  parameter\n",
        "\n",
        "#And now we have to calculate our model prediction, the loss,  and the gradients; and we will be doing this manually for the fist time.\n",
        "\n",
        "#Model prediction\n",
        "def forward(x):\n",
        "  return w*x\n",
        "\n",
        "#Loss: MSE\n",
        "def loss(y,y_hat):\n",
        "  return ((y_hat-y)**2).mean()\n",
        "\n",
        "\n",
        "#We will get rid of the manually computed gradient.\n",
        "'''\n",
        "#Gradient\n",
        "#Now we have to calculate the gradient of the loss with respect to our parameters.\n",
        "#MSE=1/N*(w*x-y)²\n",
        "#Its derivative is: dJ/dw= 1/N * 2 * x *(w*x-y) :So this is the numerical computed derivative.\n",
        "def gradient(x,y,y_hat):\n",
        "  return np.dot(2*x,y_hat-y).mean()\n",
        "'''\n",
        "\n",
        "\n",
        "#Now let's print our prediction before the training\n",
        "print(f'Prediction before training f(5)={forward(5):.3f}')\n",
        "\n",
        "#Training loop\n",
        "learning_rate= 0.01\n",
        "n_iters=61\n",
        "\n",
        "for epoch in range(n_iters):\n",
        "\n",
        "  #prediction=forward pass\n",
        "  y_pred=forward(X)\n",
        "\n",
        "  #Loss\n",
        "  l=loss(Y,y_pred)  \n",
        "\n",
        "  #Gradients=backward pass\n",
        "  '''dw=gradient(X,Y,y_pred)\n",
        "\n",
        "  #update weights (using the gradient descent algorithm)\n",
        "  w-=learning_rate* dw'''\n",
        "  l.backward() #This will calculate the gradient of our loss with respect to w--> Pytorch does all the computations for us.\n",
        "  #And now we update our weights, but here we want to be careful: This operation should not be part of our gradinent tracking graph: So this should not be part of the computational graph.\n",
        "  with torch.no_grad():\n",
        "    w-=learning_rate* w.grad #Our dw which is dLoss/dw has become now w.grad\n",
        "  #Also we must empty or zero the gradients again; because whenever we call backward, it will write our gradients and accumulate them in the w.grad attribute.\n",
        "  #Zero gradients:\n",
        "  w.grad.zero_()\n",
        "  if epoch %10==0:\n",
        "    print(f'epoch:<{epoch+1}: w= {w:.3f}, loss={l:8f}') #Every 10 epochs\n",
        "'''if epoch % 1==0: #Why %1? Because here we want for every step.\n",
        "    print(f'epoch:<{epoch+1}: w= {w:.3f}, loss={l:8f}')\n",
        "'''\n",
        "\n",
        "print(f'Prediction After training training f(5)={forward(5):.3f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxfzlujHjldY",
        "outputId": "79f7e8ed-7930-48ca-9512-052351091ede"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction before training f(5)=0.000\n",
            "epoch:<1: w= 0.300, loss=30.000000\n",
            "epoch:<11: w= 1.665, loss=1.162786\n",
            "epoch:<21: w= 1.934, loss=0.045069\n",
            "epoch:<31: w= 1.987, loss=0.001747\n",
            "epoch:<41: w= 1.997, loss=0.000068\n",
            "epoch:<51: w= 1.999, loss=0.000003\n",
            "epoch:<61: w= 2.000, loss=0.000000\n",
            "Prediction After training training f(5)=10.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Training pipeline: Model/ Loss/ Optimizer**"
      ],
      "metadata": {
        "id": "zw7Z4hewy0Ae"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#In this part, we are going to continue inshaa'Allah, and replace the manually compute loss and weight updates with pytorch loss and optimizers classes\n",
        "'''3:Prediction: Manually (1)\n",
        "      Gradients computation: Autograd (3)\n",
        "      Loss computation: Pytorch loss (2)\n",
        "      Parameter updates: Pytorch optimizer(4)'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "EGMxwC_Qy8li",
        "outputId": "1d0b3825-85ad-4e37-fb19-785c7be18dba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'3:Prediction: Manually (1)\\n      Gradients computation: Autograd (3)\\n      Loss computation: Pytorch loss (2)\\n      Parameter updates: Pytorch optimizer(4)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##Note: The general training pipeline in pytorch:\n",
        "#Typically we have 3 steps:\n",
        "#1) Design model: we design the number of inputs and outputs, and then also we define the forward pass with all the different operations or all the different layers: Design Model(input, output size, forward pass)\n",
        "#2)Costruct the loss and the optimizer\n",
        "#3) Training loop: *Compute the prediction\n",
        "#                  *The backward pass: We get the gradients and pytorch can do everything for us: We only have to define or to desing our model\n",
        "#                  *Update weights (After we have the gradients, we can then update our weights)\n",
        "#                  ->And then we iterate this a couple of time until we are done; And that's the whole pipeline."
      ],
      "metadata": {
        "id": "tbyF_DI21XMx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#We will be using a linear regression; so we use a fuction which just does a linear combination of some weights: f=wx (we don't care about the bias here)\n",
        "#Let's say f= 2*x\n",
        "#And then let's do some training samples. So let's say:\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn  #It's the neural network module, so that we can use some functions of this.\n",
        "\n",
        "'''X, Y, and w should all be tensors.'''\n",
        "X=torch.tensor([1,2,3,4],dtype=torch.float32)\n",
        "Y=torch.tensor([2,4,6,8],dtype=torch.float32)\n",
        "#And now we initialize our weights:\n",
        "w=torch.tensor(0.0,dtype=torch.float32,requires_grad=True)\n",
        "#We added requires_grad=True in the w argument since we are interested in the gradient of our loss with respect to this  parameter\n",
        "\n",
        "#And now we have to calculate our model prediction, the loss,  and the gradients; and we will be doing this manually for the fist time.\n",
        "\n",
        "#Model prediction\n",
        "def forward(x):\n",
        "  return w*x\n",
        "\n",
        "'''##############################\n",
        "#Loss: MSE\n",
        "def loss(y,y_hat):\n",
        "  return ((y_hat-y)**2).mean()\n",
        "'''\n",
        "loss= nn.MSELoss() #This is a callable function\n",
        "\n",
        "learning_rate= 0.01\n",
        "optimizer=torch.optim.SGD([w],lr=learning_rate)\n",
        "\n",
        "#We will get rid of the manually computed gradient.\n",
        "'''\n",
        "#Gradient\n",
        "#Now we have to calculate the gradient of the loss with respect to our parameters.\n",
        "#MSE=1/N*(w*x-y)²\n",
        "#Its derivative is: dJ/dw= 1/N * 2 * x *(w*x-y) :So this is the numerical computed derivative.\n",
        "def gradient(x,y,y_hat):\n",
        "  return np.dot(2*x,y_hat-y).mean()\n",
        "'''\n",
        "\n",
        "\n",
        "#Now let's print our prediction before the training\n",
        "print(f'Prediction before training f(5)={forward(5):.3f}')\n",
        "\n",
        "#Training loop\n",
        "n_iters=61\n",
        "for epoch in range(n_iters):\n",
        "\n",
        "  #prediction=forward pass\n",
        "  y_pred=forward(X)\n",
        "\n",
        "  #Loss\n",
        "  l=loss(Y,y_pred)\n",
        "\n",
        "\n",
        "  \n",
        "  l.backward()\n",
        "  #Update weights\n",
        "  optimizer.step() #which will do an optimization step\n",
        "  #And then we also still have to empty our gradients after the optimization step:\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "\n",
        "  #THEN WE DON'T NEED TO MANUALLY UPDATE OUR WEIGHTS ANYMORE\n",
        "  \"\"\"\n",
        "  #Gradients=backward pass\n",
        "  '''dw=gradient(X,Y,y_pred)\n",
        "\n",
        "  #update weights (using the gradient descent algorithm)\n",
        "  w-=learning_rate* dw'''\n",
        "  l.backward() #This will calculate the gradient of our loss with respect to w--> Pytorch does all the computations for us.\n",
        "  #And now we update our weights, but here we want to be careful: This operation should not be part of our gradinent tracking graph: So this should not be part of the computational graph.\n",
        "  with torch.no_grad():\n",
        "    w-=learning_rate* w.grad #Our dw which is dLoss/dw has become now w.grad\n",
        "  #Also we must empty or zero the gradients again; because whenever we call backward, it will write our gradients and accumulate them in the w.grad attribute.\n",
        "  #Zero gradients:\n",
        "  w.grad.zero_()\n",
        "  \"\"\"\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  if epoch %10==0:\n",
        "    print(f'epoch:<{epoch+1}: w= {w:.3f}, loss={l:8f}') #Every 10 epochs\n",
        "'''if epoch % 1==0: #Why %1? Because here we want for every step.\n",
        "    print(f'epoch:<{epoch+1}: w= {w:.3f}, loss={l:8f}')\n",
        "'''\n",
        "\n",
        "print(f'Prediction After training training f(5)={forward(5):.3f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-iJKsWFDIG9",
        "outputId": "180f58d9-c269-41a8-98c1-4a6730c52e23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction before training f(5)=0.000\n",
            "epoch:<1: w= 0.300, loss=30.000000\n",
            "epoch:<11: w= 1.665, loss=1.162786\n",
            "epoch:<21: w= 1.934, loss=0.045069\n",
            "epoch:<31: w= 1.987, loss=0.001747\n",
            "epoch:<41: w= 1.997, loss=0.000068\n",
            "epoch:<51: w= 1.999, loss=0.000003\n",
            "epoch:<61: w= 2.000, loss=0.000000\n",
            "Prediction After training training f(5)=10.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#LET'S NOW CONTINUE WITH THE STEP FOUR AND REPLACE OUR MANUALLY IMPLEMENTED FORWARD METHOD WITH A PYTORCH MODEL.\n",
        "'''4:Prediction: Pytorch model\n",
        "      Gradients computation: Autograd\n",
        "      Loss computation: Pytorch loss\n",
        "      Parameter updates: Pytorch optimizer '''\n",
        "###############ALSO WE DO NOT NEED TO INITILIZE THE WEIGHT ANYMORE SINCE OUR PYTORCH MODEL KNOWS THE PARAMETERS.\n",
        "###############MOREOVER, THE SHAPES OF INPUT AND OUTPUT HAVE BEEN CHANGED: with a number of rows is the number of samples, and for each row we have the features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "nBxISffRIFwl",
        "outputId": "6d4609b9-97fc-4ef3-ee44-ff6bf62f01e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'4:Prediction: Pytorch model\\n      Gradients computation: Autograd\\n      Loss computation: Pytorch loss\\n      Parameter updates: Pytorch optimizer '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=torch.tensor([[1],[4],[3],[5]])\n",
        "print(x.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6Xor2TrxVbJ",
        "outputId": "e40b41bd-d2ec-4ef3-e127-9cc3607e98ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#We will be using a linear regression; so we use a fuction which just does a linear combination of some weights: f=wx (we don't care about the bias here)\n",
        "#Let's say f= 2*x\n",
        "#And then let's do some training samples. So let's say:\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn  #It's the neural network module, so that we can use some functions of this.\n",
        "\n",
        "'''X, Y, and w should all be tensors.'''\n",
        "X=torch.tensor([[1],[2],[3],[4]],dtype=torch.float32)\n",
        "Y=torch.tensor([[2],[4],[6],[8]],dtype=torch.float32)\n",
        "\n",
        "\"\"\"And now we initialize our weights:\"\"\" ###WE DO NOT NEED TO INITILIZE THE WEIGHT ANYMORE SINCE OUR PYTORCH MODEL KNOWS THE PARAMETERS.\n",
        "\"\"\"w=torch.tensor(0.0,dtype=torch.float32,requires_grad=True)\n",
        "#We added requires_grad=True in the w argument since we are interested in the gradient of our loss with respect to this  parameter\n",
        "\n",
        "#And now we have to calculate our model prediction, the loss,  and the gradients; and we will be doing this manually for the fist time.\n",
        "\n",
        "#Model prediction\n",
        "def forward(x):\n",
        "  return w*x\n",
        "\"\"\"\n",
        "\n",
        "n_samples, n_features = X.shape\n",
        "print(f'n_samples= {n_samples} and n_features={n_features}') #We have in our case 4 samples with 1 feature each\n",
        "\n",
        "#And now we define our model. So this needs an input and an output size\n",
        "input_size=n_features\n",
        "output_size=n_features\n",
        "\n",
        "model=nn.Linear(input_size,output_size)   #THIS IS ONLY ONE LAYER\n",
        "'''\n",
        "#Loss: MSE\n",
        "def loss(y,y_hat):\n",
        "  return ((y_hat-y)**2).mean()\n",
        "'''\n",
        "loss= nn.MSELoss() #This is a callable function\n",
        "\n",
        "learning_rate= 0.01\n",
        "#######Now we also have to modify our optimizer here: We don't have our weights now.\n",
        "'''optimizer=torch.optim.SGD([w],lr=learning_rate)'''\n",
        "optimizer=torch.optim.SGD(model.parameters(),lr=learning_rate) #w has become model.parameters() since as we have said in the precedent cell; pytorch knows the parameters.\n",
        "\n",
        "#We will get rid of the manually computed gradient.\n",
        "'''\n",
        "#Gradient\n",
        "#Now we have to calculate the gradient of the loss with respect to our parameters.\n",
        "#MSE=1/N*(w*x-y)²\n",
        "#Its derivative is: dJ/dw= 1/N * 2 * x *(w*x-y) :So this is the numerical computed derivative.\n",
        "def gradient(x,y,y_hat):\n",
        "  return np.dot(2*x,y_hat-y).mean()\n",
        "'''\n",
        "\n",
        "\n",
        "#Now let's print our prediction before the training\n",
        "################Also here the test variable should be a tensor: So instead of 5, let's define:###################\n",
        "X_test=torch.tensor([5],dtype=torch.float32)\n",
        "\n",
        "print(f'Prediction before training f(5)={model(X_test).item():.3f}')\n",
        "\n",
        "#Training loop\n",
        "n_iters=3000\n",
        "for epoch in range(n_iters):\n",
        "\n",
        "  #prediction=forward pass\n",
        "  '''y_pred=forward(X)'''\n",
        "  y_pred=model(X)\n",
        "\n",
        "  #Loss\n",
        "  l=loss(Y,y_pred)\n",
        "  l.backward()\n",
        "  #Update weights\n",
        "  optimizer.step() #which will do an optimization step\n",
        "  #And then we also still have to empty our gradients after the optimization step:\n",
        "  optimizer.zero_grad()\n",
        " \n",
        "\n",
        "  #THEN WE DON'T NEED TO MANUALLY UPDATE OUR WEIGHTS ANYMORE\n",
        "  \"\"\"\n",
        "  #Gradients=backward pass\n",
        "  '''dw=gradient(X,Y,y_pred)\n",
        "\n",
        "  #update weights (using the gradient descent algorithm)\n",
        "  w-=learning_rate* dw'''\n",
        "  l.backward() #This will calculate the gradient of our loss with respect to w--> Pytorch does all the computations for us.\n",
        "  #And now we update our weights, but here we want to be careful: This operation should not be part of our gradinent tracking graph: So this should not be part of the computational graph.\n",
        "  with torch.no_grad():\n",
        "    w-=learning_rate* w.grad #Our dw which is dLoss/dw has become now w.grad\n",
        "  #Also we must empty or zero the gradients again; because whenever we call backward, it will write our gradients and accumulate them in the w.grad attribute.\n",
        "  #Zero gradients:\n",
        "  w.grad.zero_()\n",
        "  \"\"\"\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  if epoch %1000==0:\n",
        "    #If we want to print them, we have to unµpack them.\n",
        "    [w,b]=model.parameters() #w is a list of list\n",
        "    print(f'epoch:<{epoch+1}: w= {w[0][0].item():.3f}, loss={l:8f}') #Every 10 epochs\n",
        "'''if epoch % 1==0: #Why %1? Because here we want for every step.\n",
        "    print(f'epoch:<{epoch+1}: w= {w:.3f}, loss={l:8f}')\n",
        "'''\n",
        "\n",
        "print(f'Prediction After training training f(5)={model(X_test).item():.3f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54phewqQL51t",
        "outputId": "0b7ea1af-75c8-4ff5-923b-a59e32e9928a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_samples= 4 and n_features=1\n",
            "Prediction before training f(5)=-3.062\n",
            "epoch:<1: w= -0.185, loss=52.031708\n",
            "epoch:<1001: w= 1.989, loss=0.000172\n",
            "epoch:<2001: w= 1.999, loss=0.000000\n",
            "Prediction After training training f(5)=10.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#In our case, the model is constituted from one layer; we have done that by using: model=nn.Linear(input_size,output_size)   \n",
        "#But let's say we need a custom model; so let's write a custom linear regression model:\n",
        "\n",
        "class LinearRegression(nn.Module): \n",
        "  def __init__(self,input_dim,output_dim): #init method #These input_dim and output_dim variables equal to n_features: In our previous case it equals to 1\n",
        "    super(LinearRegression,self).__init__() #We define here super; a super class of linear regression \n",
        "    #define layers\n",
        "    self.lin= nn.Linear(input_dim,output_dim) #lin for linear layer \n",
        "  \n",
        "  #We also have to implement the forward pass in our class\n",
        "  def forward(self,x):\n",
        "    return self.lin(x)\n",
        "\n",
        "model=LinearRegression(input_size, output_size)\n"
      ],
      "metadata": {
        "id": "gbtv6_7gW2gR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#So now Pytorch can do most of the work for us.. Of course we still have to design our model, and have to know which loss and optimizer we want to use.. But we don't have to worry about the \n",
        "#underlying algorithms anymore."
      ],
      "metadata": {
        "id": "b8FBP8flmKfE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Linear Regression**"
      ],
      "metadata": {
        "id": "2kF0h_gVmzQn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#This would be a kind of repetition of what we say in the previous parts.\n"
      ],
      "metadata": {
        "id": "ljV6uKcQmwkQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Note: The general training pipeline in pytorch:\n",
        "#Typically we have 3 steps:\n",
        "#1) Design model: we design the number of inputs and outputs, and then also we define the forward pass with all the different operations or all the different layers: Design Model(input, output size, forward pass)\n",
        "#2)Costruct the loss and the optimizer\n",
        "#3) Training loop: *Compute the prediction\n",
        "#                  *The backward pass: We get the gradients and pytorch can do everything for us: We only have to define or to desing our model.\n",
        "#                  *Update weights (After we have the gradients, we can then update our weights)\n",
        "#                  ->And then we iterate this a couple of time until we are done; And that's the whole pipeline."
      ],
      "metadata": {
        "id": "KY5zGBDBEwXJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from sklearn import datasets #We want to generate a regression dataset\n",
        "import matplotlib.pyplot as plt\n",
        "#And then we do our 3 steps "
      ],
      "metadata": {
        "id": "WgtJOIzKEw2q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "############(0)PREPARE DATA############\n",
        "#Let's generate a regression dataset, and we can do so by:\n",
        "X_numpy,y_numpy=datasets.make_regression(n_samples=100,n_features=1,noise=20,random_state=1) #the dtype within here is double.\n",
        "#Then we want to convert this to a torch tensor.\n",
        "X=torch.from_numpy(X_numpy.astype(np.float32)) #We want to convert this into float32 data type before. If we use a double here, then we will run into some errors later, and we do the same thing with y.\n",
        "y=torch.from_numpy(y_numpy.astype(np.float32))\n",
        "#print(f'Before: y_shape equals {y.shape}')\n",
        "#print(\"y before=\",y)\n",
        "#Now let's reshape our y, because right now it has only one row, and we want to make it a column vector; So we want to put each value in one row, and the whole shape has only one column:\n",
        "y=y.view(y.shape[0],1)\n",
        "#print(f'After: y_shape equals {y.shape}')\n",
        "#print(\"y after=\",y)\n",
        "\n",
        "n_samples,n_features=y.shape\n",
        "print(f'the number of samples equals {n_samples}, and the number of features equals {n_features}')"
      ],
      "metadata": {
        "id": "4chkGungFrIQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7dc1772-2930-40a6-ac61-6a02997c70c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the number of samples equals 100, and the number of features equals 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "############(1)MODEL############\n",
        "input_size=n_features #which equals one in our case\n",
        "output_size=1\n",
        "model=nn.Linear(input_size,output_size)"
      ],
      "metadata": {
        "id": "pU2KN4ueFJp8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "############(2)DEFINE THE LOSS AND THE OPTIMIZER############\n",
        "criterion = nn.MSELoss()\n",
        "learning_rate= 0.01\n",
        "optimizer=torch.optim.SGD(model.parameters(),lr=learning_rate)"
      ],
      "metadata": {
        "id": "2cuNanc7Fejx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "############3)THE TRAINING LOOP############\n",
        "num_epochs=100\n",
        "for epoch in range(num_epochs):\n",
        "  #Forward pass\n",
        "  y_pred=model(X)\n",
        "  #Loss\n",
        "  l=criterion(y,y_pred)\n",
        "  #Backward pass\n",
        "  l.backward() #This will do the back propagation and calculate the gradients for us.\n",
        "  #Update weights\n",
        "  optimizer.step() #which will do an optimization step\n",
        "  #And then we also still have to empty our gradients after the optimization step, because whenever we call the backward function ,this will sum up the gradients into the .grad atribute:\n",
        "  optimizer.zero_grad()\n",
        "  #Let's print some informations:\n",
        "  if (epoch+1) % 10 == 0:\n",
        "    print(f'epoch: {epoch+1}, loss = {loss.item():.4f}')\n",
        "\n",
        "\n",
        "predicted = model(X).detach().numpy() \n",
        "#Here we call our final model with all the data #Why detach? We want to prevent this operation from being tracked in our graph; in our computation graph; The X tensor has the required \n",
        "#gradients arguemen4t set to true, but now we want this to fall to be false for the predicted variable: So this will generate a new tensor where our gradient calculation attribute is false.\n",
        "plt.plot(X_numpy,y_numpy,'ro') #'ro': for red dots. #to plot all the data\n",
        "plt.plot(X_numpy,predicted,'b') #To plot our generated or approximated function\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "id": "03UBSXhHFkEs",
        "outputId": "9530158c-4c3d-4322-d39a-8a9b2b3a8799"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 10, loss = 332.5676\n",
            "epoch: 20, loss = 332.5676\n",
            "epoch: 30, loss = 332.5676\n",
            "epoch: 40, loss = 332.5676\n",
            "epoch: 50, loss = 332.5676\n",
            "epoch: 60, loss = 332.5676\n",
            "epoch: 70, loss = 332.5676\n",
            "epoch: 80, loss = 332.5676\n",
            "epoch: 90, loss = 332.5676\n",
            "epoch: 100, loss = 332.5676\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is problem in the previous cell.. The correct one is the next following.."
      ],
      "metadata": {
        "id": "JJhxaxFmVdXp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 0) Prepare data\n",
        "X_numpy, y_numpy = datasets.make_regression(n_samples=100, n_features=1, noise=20, random_state=4)\n",
        "\n",
        "# cast to float Tensor\n",
        "X = torch.from_numpy(X_numpy.astype(np.float32))\n",
        "y = torch.from_numpy(y_numpy.astype(np.float32))\n",
        "y = y.view(y.shape[0], 1)\n",
        "\n",
        "n_samples, n_features = X.shape\n",
        "\n",
        "# 1) Model\n",
        "# Linear model f = wx + b\n",
        "input_size = n_features\n",
        "output_size = 1\n",
        "model = nn.Linear(input_size, output_size)\n",
        "\n",
        "# 2) Loss and optimizer\n",
        "learning_rate = 0.01\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)  \n",
        "\n",
        "# 3) Training loop\n",
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "    # Forward pass and loss\n",
        "    y_predicted = model(X)\n",
        "    loss = criterion(y_predicted, y)\n",
        "    \n",
        "    # Backward pass and update\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # zero grad before new step\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        print(f'epoch: {epoch+1}, loss = {loss.item():.4f}')\n",
        "\n",
        "# Plot\n",
        "predicted = model(X).detach().numpy()\n",
        "\n",
        "plt.plot(X_numpy, y_numpy, 'ro')\n",
        "plt.plot(X_numpy, predicted, 'b')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "rPyTu1xGVIOP",
        "outputId": "66333136-53b0-4c1c-eec0-21875b2cc552"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 10, loss = 4138.6221\n",
            "epoch: 20, loss = 2914.6682\n",
            "epoch: 30, loss = 2080.3445\n",
            "epoch: 40, loss = 1511.4946\n",
            "epoch: 50, loss = 1123.5663\n",
            "epoch: 60, loss = 858.9636\n",
            "epoch: 70, loss = 678.4438\n",
            "epoch: 80, loss = 555.2638\n",
            "epoch: 90, loss = 471.1940\n",
            "epoch: 100, loss = 413.8060\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Logistic regression**"
      ],
      "metadata": {
        "id": "7_8QK_5tUx4W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Once again we implement our typical pytorch pipeline with these three steps:\n",
        "#1) Design model: we design the number of inputs and outputs, and then also we define the forward pass with all the different operations or all the different layers: Design Model(input, output size, forward pass)\n",
        "#2)Costruct the loss and the optimizer\n",
        "#3) Training loop: *Compute the prediction\n",
        "#                  *The backward pass: We get the gradients and pytorch can do everything for us: We only have to define or to desing our model\n",
        "#                  *Update weights (After we have the gradients, we can then update our weights)\n",
        "#                  ->And then we iterate this a couple of time until we are done; And that's the whole pipeline."
      ],
      "metadata": {
        "id": "Xt8PyOLuU1P9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#The code here should be very similar the linear regression's one"
      ],
      "metadata": {
        "id": "-5HbOmVsV3Rn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.random.mtrand import random_sample\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler #Because we want to scale our features\n",
        "from sklearn.model_selection import train_test_split #Because we want to have a seperation of training and testing data\n",
        "import numpy as np\n",
        "##########0)Prepare the data\n",
        "#We will load the breast cancer dataset from sklearn\n",
        "bc=datasets.load_breast_cancer()  #This is a binary classification problem where we can predict cancer based on the input features\n",
        "X, y=bc.data, bc.target\n",
        "n_samples,n_features=X.shape\n",
        "#print(f'n_samples:{n_samples}, and n_features= {n_features}')\n",
        "\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=1234)\n",
        "\n",
        "\n",
        "#Now we want to scale our features\n",
        "#Here we set up a standard scaler which will make our features to have zero mean and unit variance(https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html)\n",
        "sc=StandardScaler() #This is always recommended to do when we want to deal with a logistic regression.\n",
        "X_train=sc.fit_transform(X_train)\n",
        "X_test=sc.transform(X_test) #Here we only transform it.\n",
        "#The fit(data) method is used to compute the mean and std dev for a given feature to be used further for scaling. The transform(data) method is used to perform scaling using mean and std dev calculated \n",
        "#using the . fit() method. The fit_transform() method does both fits and transform.\n",
        "\n",
        "\n",
        "#Now we would like to convert the data to torch tensors.\n",
        "print(X_train)\n",
        "\n",
        "X_train=torch.from_numpy(X_train.astype(np.float32))\n",
        "X_test=torch.from_numpy(X_test.astype(np.float32))\n",
        "y_test=torch.from_numpy(y_test.astype(np.float32))\n",
        "y_train=torch.from_numpy(y_train.astype(np.float32))\n",
        "#And now as a last step; is to reshape our y tensor:\n",
        "\n",
        "y_train=y_train.view(y_train.shape[0],1) #We are making it as a column vector;So we want to put each value in one row only with only one column\n",
        "y_test=y_test.view(y_test.shape[0],1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pi9Brshh0oVS",
        "outputId": "b1d98225-d0c0-49ab-d774-0a1d98967618"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.36180827 -0.26521011 -0.31715702 ... -0.07967528 -0.52798733\n",
            "   0.2506337 ]\n",
            " [-0.8632675   0.71560604 -0.85646012 ... -0.76980239  0.44312729\n",
            "  -0.20987332]\n",
            " [-0.4334453   0.32513895 -0.41286667 ... -0.06601541 -1.1169427\n",
            "   0.0329492 ]\n",
            " ...\n",
            " [-0.479293   -0.17689018 -0.45697634 ... -0.20261414  0.18670009\n",
            "   0.17414996]\n",
            " [ 1.16835876 -0.15364809  1.17466524 ...  0.26789258  0.19828067\n",
            "  -0.23394164]\n",
            " [-0.40765597 -1.29715887 -0.42826344 ... -0.78042674 -0.88036793\n",
            "  -0.80355834]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##########1)Model\n",
        "#our model is a linear combination of weights and a bias, and then in the logistic regression case, we apply a sigmoid function in the end: #f=wx+b, sigmoid at the end.\n",
        "class LogisticRegression(nn.Module):\n",
        "  #which means: This must be derived from nn.Module\n",
        "  def __init__(self,n_input_features):\n",
        "    super(LogisticRegression,self).__init__()\n",
        "    self.linear=nn.Linear(n_input_features,1) #1 is the output size; we only have one output; One value; One class label. \n",
        "  \n",
        "  def forward(self,x):\n",
        "    y_predicted=torch.sigmoid(self.linear(x))\n",
        "    return y_predicted\n",
        "\n",
        "model=LogisticRegression(n_features) #So now our layer is of size 30 by 1 \n",
        "\n",
        "##########2)Loss and optimizer\n",
        "#The loss function now is different than in the linear regression case\n",
        "criterion=nn.BCELoss()   #Binary cross entropy loss\n",
        "learning_rate=0.01\n",
        "optimizer= torch.optim.SGD(model.parameters(),lr=learning_rate) #Inside this function is the parameters that we want to optimize\n",
        "\n",
        "\n",
        "##########3)Training loop\n",
        "num_epochs=100\n",
        "for epoch in range(num_epochs):\n",
        "  #Forward pass\n",
        "  y_pred=model(X_train)\n",
        "\n",
        "  #Loss\n",
        "  l=criterion(y_pred,y_train)\n",
        "\n",
        "  #Backward pass\n",
        "  l.backward() #This will do the back propagation and calculate the gradients for us.\n",
        "\n",
        "  #Update weights\n",
        "  optimizer.step() #which will do an optimization step: Pytorch will do all the update calculation for us.\n",
        "  #And then we also still have to empty our gradients after the optimization step, because whenever we call the backward function ,this will sum up the gradients into the .grad atribute:\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  if (epoch+1) % 10 ==0:\n",
        "    print(f'epoch:{epoch+1}, and the loss={l.item():.4f}')\n",
        "\n",
        "#Now, let's evaluate our model; So the evaluation should not be part of our computational graph where we want to track the history, So:\n",
        "with torch.no_grad():\n",
        "  y_predicted =model(X_test)\n",
        "  #Let's convert this to class labels: 0 or 1\n",
        "  #Remember that the sigmoid function will return a value between 0 and 1; And if this is larger than .5 we say that this is class 1, otherwise 0\n",
        "  y_predicted_cls=y_predicted.round() #If we didn't do the torch.no_grad(), then this would be part of the computational graph and it would track the gradient calculations for us.. Here we don't need this because we are done.\n",
        "  #Now let's calculate the accuracy\n",
        "  acc=y_predicted_cls.eq(y_test).sum() / float(y_test.shape[0]) #We have used the equals function (eq)\n",
        "  print(f'accuracy={acc:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQ2G-XcJWL90",
        "outputId": "6e99ab59-8439-4337-af28-5628862500a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:10, and the loss=0.6400\n",
            "epoch:20, and the loss=0.5163\n",
            "epoch:30, and the loss=0.4399\n",
            "epoch:40, and the loss=0.3882\n",
            "epoch:50, and the loss=0.3508\n",
            "epoch:60, and the loss=0.3223\n",
            "epoch:70, and the loss=0.2998\n",
            "epoch:80, and the loss=0.2814\n",
            "epoch:90, and the loss=0.2660\n",
            "epoch:100, and the loss=0.2530\n",
            "accuracy=0.8772\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#DIFFERENCE BETWEEN LINEAR REGRESSION AND LOGISTIC REGRESSION:\n",
        "\n",
        "#The biggest difference is that linear regression has the dependent variable as a continuous variable. Meaning, you can do math with it. 1 + 2 = 3.\n",
        "#Logistic regression is more for binary/categorical variables. Category 1 + Category 2 does not equal Category 3.\n",
        "#There are some other minor things going on behind the scenes, but that's the gist of it. Linear regression utilizes the least square method.\n",
        "#Logistic regression uses maximum likely hood. Linear regression finds the best fit line. Logistic regression uses an S-curve to best classify things. \n",
        "#Linear regression may or may not have collinearity, whereas logistic regression shouldn't.\n",
        "\n",
        "#Logistic regression is basically taking a multiple linear regression and squashing it through a logistic function: You can generelize a logistic function to classify multiple different categories, and \n",
        "#if you don't want to stick with conventional statistical methods, you can use any number of ML methods instead."
      ],
      "metadata": {
        "id": "DNwNGKSJ6RcN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#DIFFERENCE BETWEEN REGRESSION AND CLASSIFICATION:\n",
        "#The output from regression is real numbers, however for classification it is classes or categories(it could be integers that represent classes); \n",
        "#And there's different models  that can be for both regression and classification"
      ],
      "metadata": {
        "id": "owWTzRI5cX24"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Dataset and dataloader**"
      ],
      "metadata": {
        "id": "ELF6i6-Ms6FN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Code for processing data samples can get messy and hard to maintain; we ideally want our dataset code to be decoupled from our model training code for better readability and modularity.\n",
        "#PyTorch provides two data primitives: torch.utils.data.DataLoader and torch.utils.data.Dataset that allow you to use pre-loaded datasets as well as your own data. \n",
        "#Dataset stores the samples and their corresponding labels, and DataLoader wraps an iterable around the Dataset to enable easy access to the samples.\n",
        "#PyTorch domain libraries provide a number of pre-loaded datasets (such as FashionMNIST) that subclass torch.utils.data.Dataset and implement functions specific to the particular data.\n",
        "#They can be used to prototype and benchmark your model. "
      ],
      "metadata": {
        "id": "i0dKH5-LaiIr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###LOADING A DATASET\n",
        "#Here is an example of how to load the Fashion-MNIST dataset from TorchVision. Fashion-MNIST is a dataset of Zalando’s article images consisting of 60,000 training examples and 10,000 test examples. Each example comprises a 28×28 grayscale image and an associated label from one of 10 classes.\n",
        "#we load the FashionMNIST Dataset with the following parameters:\n",
        "#root is the path where the train/test data is stored,\n",
        "#train specifies training or test dataset,\n",
        "#download=True downloads the data from the internet if it’s not available at root.\n",
        "#transform and target_transform specify the feature and label transformations\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")\n",
        "\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423,
          "referenced_widgets": [
            "43e4739fabb447c3a3b685e2e6c50d46",
            "5d0fdf9c002a45049bb5f22114613395",
            "f84e78d925ca41a49c29f524e7a0d71d",
            "266ba5dd12b5444c9d9357d8cf4354b5",
            "21af79cb3ac1425592462a56261777e0",
            "6d9bf1bdc3cd475fb759dfc0d65b119c",
            "0044c573ce814f9dae0d26e70ee721f7",
            "d2eaaa6e826d4d858198fa45c4a83fc4",
            "55ad2026281d4a4aad7d29e3c204ba4b",
            "13e1bb50d3b74650a46b91b12da8f467",
            "9abfe2382c5c41c9bdf3e8c766fdde27",
            "b7f5144837884439aa79ae9066c9d594",
            "3a446c89fa4343e1a50edba66f1cca19",
            "44dab35374934840a1082587a77563f8",
            "c645236658a34465bf1fe2323c66c33e",
            "42e835125ce34f958291e3d0abc72c91",
            "46927d896d1646cda426e33ea2eb2069",
            "679005bd1ace42b7b5cf5551f7441eda",
            "c7dddd17eff443389077542d70170d47",
            "311e78e9a1fa465c8b40b477f14038de",
            "ba721330e99f4facabba27b7e69e9637",
            "da5b46638f3d450fb7c7085f9cf51012",
            "919d17356dd249bd8328b26f6394bead",
            "5a9b034b36bb4c1da9f5c30e9d7ba340",
            "cd5a723f5ba443b69f37b218bbc7cd36",
            "74dcba7430084d42b7f15a429c1917d8",
            "184021ea850a464f9a61f68c4efc732f",
            "adc8f53d45784fa595b32098a2b3300b",
            "341d4e4e42a44160b14b50d3f5ad16da",
            "71deebae3d844a83877a16d20699cf5b",
            "0bedf18baa554d378f4d2628f642a96b",
            "ad35a8e43a23434b9e2d6dcfa257b161",
            "5f106fa4b06c476da6a62b13bb63298f",
            "70ad99869fc443de9a1123598e198a1c",
            "8b1c496cc419445aa20232f75022b561",
            "64b6ee96232b45b390e5d01ddd8e2452",
            "df7eff329ac846b5ad1dde7c1e536501",
            "55e5fea1146545708f939603fadd8e39",
            "b3be6f4adc61425fb12dae530d1c7c37",
            "ee36db3326b54af4a383803dc631270b",
            "2040ebc6235949f79a76a724ad0acbc4",
            "ddd93a1fb6504e228938d0596f1d7935",
            "306b6a0bee9b4dd8b3e307d18e66e2b6",
            "feb841444fdd4aa6961b4d344edfd531"
          ]
        },
        "id": "unCV8g0-byFK",
        "outputId": "a5c35bc0-dac9-4add-867e-138004f6a253"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/26421880 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "43e4739fabb447c3a3b685e2e6c50d46"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/29515 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b7f5144837884439aa79ae9066c9d594"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/4422102 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "919d17356dd249bd8328b26f6394bead"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/5148 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "70ad99869fc443de9a1123598e198a1c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###Iterating and visualizing the Dataset\n",
        "#We can index Datasets manually like a list: training_data[index]. We use matplotlib to visualize some samples in our training data.\n",
        "labels_map = {\n",
        "    0: \"T-Shirt\",\n",
        "    1: \"Trouser\",\n",
        "    2: \"Pullover\",\n",
        "    3: \"Dress\",\n",
        "    4: \"Coat\",\n",
        "    5: \"Sandal\",\n",
        "    6: \"Shirt\",\n",
        "    7: \"Sneaker\",\n",
        "    8: \"Bag\",\n",
        "    9: \"Ankle Boot\",\n",
        "}\n",
        "figure = plt.figure(figsize=(8, 8))\n",
        "cols, rows = 3, 3\n",
        "for i in range(1, cols * rows + 1):\n",
        "    sample_idx = torch.randint(len(training_data), size=(1,)).item()\n",
        "    img, label = training_data[sample_idx]\n",
        "    figure.add_subplot(rows, cols, i)\n",
        "    plt.title(labels_map[label])\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        },
        "id": "xT4cXqTwc-9Y",
        "outputId": "691f0ea4-2d94-4d98-bb20-c3027783658c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x576 with 9 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "######Creating a custom dataset for your files"
      ],
      "metadata": {
        "id": "5lRu8Mx3lPL2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#A custom Dataset class must implement three functions: __init__, __len__, and __getitem__. Take a look at this implementation; the FashionMNIST images are stored in a directory img_dir,\n",
        "#and their labels are stored separately in a CSV file annotations_file.\n",
        "#In the next sections, we’ll break down what’s happening in each of these functions."
      ],
      "metadata": {
        "id": "qZabD9dBlib_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from torchvision.io import read_image\n",
        "\n",
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None): #Here we set the attributes; We have four; img_labes, img_dir, transform, target_transform\n",
        "        self.img_labels = pd.read_csv(annotations_file)\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
        "        image = read_image(img_path)  #It identifies the image's location on disk, and using this command, it converts that to a tensor using \"read_image\"\n",
        "        label = self.img_labels.iloc[idx, 1]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        if self.target_transform:\n",
        "            label = self.target_transform(label)\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "Gq2sZI1wgQQn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''__init__\n",
        "The __init__ function is run once when instantiating the Dataset object. We initialize the directory containing the images, the annotations file, and both transforms (covered in more detail in the next section).\n",
        "\n",
        "The labels.csv file looks like:\n",
        "\n",
        "tshirt1.jpg, 0\n",
        "tshirt2.jpg, 0\n",
        "......\n",
        "ankleboot999.jpg, 9'''\n",
        "\n",
        "'''__len__\n",
        "The __len__ function returns the number of samples in our dataset.\n",
        "'''\n",
        "\n",
        "\n",
        "'''__getitem__\n",
        "The __getitem__ function loads and returns a sample from the dataset at the given index idx. Based on the index, it identifies the image’s location on disk, \n",
        "converts that to a tensor using read_image, retrieves the corresponding label from the csv data in self.img_labels, calls the transform functions on them (if applicable),\n",
        "and returns the tensor image and corresponding label in a tuple.\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "MDbRS6rZn39U",
        "outputId": "028fb5d2-336a-4931-f3d0-5e9a74771834"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'__getitem__\\nThe __getitem__ function loads and returns a sample from the dataset at the given index idx. Based on the index, it identifies the image’s location on disk, \\nconverts that to a tensor using read_image, retrieves the corresponding label from the csv data in self.img_labels, calls the transform functions on them (if applicable),\\nand returns the tensor image and corresponding label in a tuple.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "########Preparing your data for training with DataLoaders###########\n",
        "\n",
        "#The Dataset retrieves our dataset’s features and labels one sample at a time. While training a model, we typically want to pass samples in “minibatches”,\n",
        "#reshuffle the data at every epoch to reduce model overfitting, and use Python’s multiprocessing to speed up data retrieval.\n",
        "#DataLoader is an iterable that abstracts this complexity for us in an easy API.\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
        "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True) #??????????? I DIDN'T UNDERSTAND THIS.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "########Iterate through the DataLoader###########\n",
        "\n",
        "#We have loaded that dataset into the DataLoader and can iterate through the dataset as needed. \n",
        "#Each iteration below returns a batch of train_features and train_labels (containing batch_size=64 features and labels respectively).\n",
        "#Because we specified shuffle=True, after we iterate over all batches the data is shuffled (for finer-grained control over the data loading order, take a look at Samplers).\n",
        "# Display image and label.\n",
        "train_features, train_labels = next(iter(train_dataloader))\n",
        "print(f\"Feature batch shape: {train_features.size()}\")\n",
        "print(f\"Labels batch shape: {train_labels.size()}\")\n",
        "img = train_features[0].squeeze()\n",
        "label = train_labels[0]\n",
        "plt.imshow(img, cmap=\"gray\")\n",
        "plt.show()\n",
        "print(f\"Label: {label}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "RERSeBgjn_DV",
        "outputId": "a5f62d4c-e6f1-4686-87cd-1218086ada5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature batch shape: torch.Size([128, 1, 28, 28])\n",
            "Labels batch shape: torch.Size([128])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label: 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2nd code for datasets and dataloaders:"
      ],
      "metadata": {
        "id": "SP1THCkivbvo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "# gradient computation etc. not efficient for whole data set\n",
        "# -> divide dataset into small batches\n",
        "\n",
        "'''\n",
        "# training loop\n",
        "for epoch in range(num_epochs):\n",
        "    # loop over all batches\n",
        "    for i in range(total_batches):\n",
        "        batch_x, batch_y = ...\n",
        "'''\n",
        "# epoch = one forward and backward pass of ALL training samples\n",
        "# batch_size = number of training samples used in one forward/backward pass #العدد متاع البيانات إلى باش يصلح بالنسبة ليهم كل مرة\n",
        "# epoch = one forward and backward pass of ALL training samples\n",
        "# batch_size = number of training samples used in one forward/backward pass\n",
        "# --> DataLoader can do the batch computation for us\n",
        "# Implement a custom Dataset:\n",
        "# inherit Dataset\n",
        "# implement __init__ , __getitem__ , and __len__\n",
        "\n",
        "class nxtDataset(Dataset):\n",
        "\n",
        "    def __init__(self):\n",
        "        # Initialize data, download, etc.\n",
        "        # read with numpy or pandas\n",
        "        xy = np.loadtxt('./data/nxt/nxt.csv', delimiter=',', dtype=np.float32, skiprows=1)\n",
        "        self.n_samples = xy.shape[0]\n",
        "\n",
        "        # here the first column is the class label, the rest are the features\n",
        "        self.x_data = torch.from_numpy(xy[:, 1:]) # size [n_samples, n_features]\n",
        "        self.y_data = torch.from_numpy(xy[:, [0]]) # size [n_samples, 1]\n",
        "        #n_samples, x_data, and y_data are the three attributes of our class\n",
        "\n",
        "    # support indexing such that dataset[i] can be used to get i-th sample\n",
        "    def __getitem__(self, index):\n",
        "        return self.x_data[index], self.y_data[index]\n",
        "\n",
        "    # we can call len(dataset) to return the size\n",
        "    def __len__(self):\n",
        "        return self.n_samples\n",
        "\n",
        "#Create dataset\n",
        "dataset = nxtDataset()\n",
        "\n",
        "# get first sample and unpack\n",
        "first_data = dataset[0] #Using the __get__ function\n",
        "features, labels = first_data\n",
        "print(features, labels)\n",
        "\n",
        "# Load whole dataset with DataLoader\n",
        "# shuffle: shuffle data, good for training\n",
        "# num_workers: faster loading with multiple subprocesses\n",
        "# !!! IF YOU GET AN ERROR DURING LOADING, SET num_workers TO 0 !!!\n",
        "\n",
        "train_loader = DataLoader(dataset=dataset,\n",
        "                          batch_size=4,\n",
        "                          shuffle=True,\n",
        "                          num_workers=2) #This might make loading faster, because it's using multiple subprocesses.\n",
        "\n",
        "# convert to an iterator and look at one random sample\n",
        "dataiter = iter(train_loader)\n",
        "data = dataiter.next()\n",
        "features, labels = data #unpacking\n",
        "print(features, labels)\n",
        "\n",
        "#Now we can also iterate over the whole dataloader; Not only to get the \"next\" item; by doing a dummy trzining loop.\n",
        "\n",
        "# Dummy Training loop\n",
        "num_epochs = 2\n",
        "total_samples = len(dataset)\n",
        "n_iterations = math.ceil(total_samples/4) # Math.ceil() function always rounds up and returns the smaller integer greater than or equal to a given number.\n",
        "print(total_samples, n_iterations)\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (inputs, labels) in enumerate(train_loader):\n",
        "    #This is the second loop; The loop over the train loader.\n",
        "        # here: 178 samples, batch_size = 4, n_iters=178/4=44.5 -> 45 iterations\n",
        "        # Run your training process\n",
        "        if (i+1) % 5 == 0:\n",
        "            print(f'Epoch: {epoch+1}/{num_epochs}, Step {i+1}/{n_iterations}| Inputs {inputs.shape} | Labels {labels.shape}')\n",
        " "
      ],
      "metadata": {
        "id": "Ig8DgsjqsbWu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Also pytorch has some already built-in datasets;torchvision.datasets\n",
        "# e.g. MNIST, Fashion-MNIST, CIFAR10, COCO\n",
        "#For instance: torchvision.datasets.MNIST()"
      ],
      "metadata": {
        "id": "TK6UmQRm3Hme"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Dataset transforms**"
      ],
      "metadata": {
        "id": "XtzjeDop_uZt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "\n",
        "dataset=torchvision.datasets.MNIST(\n",
        "    root='./data',\n",
        "    transform=torchvision.transforms.ToTensor() #This function will convert images or numpy arrays to tensors, and pytorch already has a lot of transforms implemented; https://pytorch.org/vision/stable/transforms.html\n",
        ")"
      ],
      "metadata": {
        "id": "yw3G3RgiAeq4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#We are going to make use of the precedent code, the nxt, by adding transforms.\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "# gradient computation etc. not efficient for whole data set\n",
        "# -> divide dataset into small batches\n",
        "\n",
        "'''\n",
        "# training loop\n",
        "for epoch in range(num_epochs):\n",
        "    # loop over all batches\n",
        "    for i in range(total_batches):\n",
        "        batch_x, batch_y = ...\n",
        "'''\n",
        "# epoch = one forward and backward pass of ALL training samples\n",
        "# batch_size = number of training samples used in one forward/backward pass #العدد متاع البيانات إلى باش يصلح بالنسبة ليهم كل مرة\n",
        "# epoch = one forward and backward pass of ALL training samples\n",
        "# batch_size = number of training samples used in one forward/backward pass\n",
        "# --> DataLoader can do the batch computation for us\n",
        "# Implement a custom Dataset:\n",
        "# inherit Dataset\n",
        "# implement __init__ , __getitem__ , and __len__\n",
        "\n",
        "class nxtDataset(Dataset):\n",
        "\n",
        "    def __init__(self,transform=None):   ''''Here we added'''\n",
        "     \n",
        "        xy = np.loadtxt('./data/nxt/nxt.csv', delimiter=',', dtype=np.float32, skiprows=1)\n",
        "        self.n_samples = xy.shape[0]\n",
        "\n",
        "        '''Note that we do not convert to tensor here'''\n",
        "        self.x = xy[:, 1:] '''We are going  to leave this as a numpy array.. and then let's implement a ToTensor class which will then be passed to our dataset'''\n",
        "        self.y=  xy[:, [0]]\n",
        "        self.transform=transform '''Here we added''' #and we also have to make some changes to our __getitem__ function\n",
        "    \n",
        "    '''#Here we would like to apply a transform if it is available'''\n",
        "    def __getitem__(self, index):\n",
        "        sample=self.x_data[index], self.y_data[index]\n",
        "\n",
        "        if self.transform:\n",
        "          #which is same like !=None\n",
        "          sample=self.transform(sample)\n",
        "        return sample\n",
        "    def __len__(self):\n",
        "        return self.n_samples\n",
        "\n",
        "'''Here we added'''\n",
        "#Now, let's create some custom transform classes: \n",
        "class ToTensor():\n",
        "  '''The only thing we need to implement is __call__ method'''\n",
        "  def __class__(self,sample):\n",
        "    #So this is a callable object\n",
        "    #What we do first here is that we unpack our samples\n",
        "    inputs,targets=sample\n",
        "    return torch.from_numpy(inputs), torch.from_numpy(targets)\n",
        "\n",
        "#Let's add now another custom transform\n",
        "class MulTransform():\n",
        "  def __init__(self,factor):\n",
        "    self.factor=factor\n",
        "\n",
        "  def __class__(self,sample):\n",
        "    inputs,target=sample #Unpacking the sample\n",
        "    inputs*=self.factor\n",
        "    return inputs,target\n",
        "    return\n",
        "\n",
        "''''The following is newely added'''\n",
        "#Create dataset\n",
        "dataset = nxtDataset(transform=ToTensor)\n",
        "\n",
        "# get first sample and unpack\n",
        "first_data = dataset[0] #Using the __get__ function\n",
        "features, labels = first_data\n",
        "print(features, labels)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "composed=torchvision.transforms.Compose([ToTensor(),MulTransform(2)])\n",
        "dataset2=nxtDataset(transform=composed)\n",
        "# get first sample and unpack\n",
        "first_data = dataset[0] #Using the __get__ function\n",
        "features, labels = first_data\n",
        "print(features, labels)\n",
        "'''And finishes here'''\n",
        "\n",
        "\n",
        "\n",
        "# Load whole dataset with DataLoader\n",
        "# shuffle: shuffle data, good for training\n",
        "# num_workers: faster loading with multiple subprocesses\n",
        "# !!! IF YOU GET AN ERROR DURING LOADING, SET num_workers TO 0 !!!\n",
        "\n",
        "train_loader = DataLoader(dataset=dataset,\n",
        "                          batch_size=4,\n",
        "                          shuffle=True,\n",
        "                          num_workers=2) #This might make loading faster, because it's using multiple subprocesses.\n",
        "\n",
        "# convert to an iterator and look at one random sample\n",
        "dataiter = iter(train_loader)\n",
        "data = dataiter.next()\n",
        "features, labels = data #unpacking\n",
        "print(features, labels)\n",
        "\n",
        "#Now we can also iterate over the whole dataloader; Not only to get the \"next\" item; by doing a dummy trzining loop.\n",
        "\n",
        "# Dummy Training loop\n",
        "num_epochs = 2\n",
        "total_samples = len(dataset)\n",
        "n_iterations = math.ceil(total_samples/4) # Math.ceil() function always rounds up and returns the smaller integer greater than or equal to a given number.\n",
        "print(total_samples, n_iterations)\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (inputs, labels) in enumerate(train_loader):\n",
        "    #This is the second loop; The loop over the train loader.\n",
        "        # here: 178 samples, batch_size = 4, n_iters=178/4=44.5 -> 45 iterations\n",
        "        # Run your training process\n",
        "        if (i+1) % 5 == 0:\n",
        "            print(f'Epoch: {epoch+1}/{num_epochs}, Step {i+1}/{n_iterations}| Inputs {inputs.shape} | Labels {labels.shape}')\n",
        " "
      ],
      "metadata": {
        "id": "o85gVo2qHRzw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Softmax & cross-entropy**"
      ],
      "metadata": {
        "id": "QGlap62a8gl2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##These are one of the most common functions used in neural networks\n",
        "#   *Softmax: S(Yi)=e⁽Yi⁾/ ‎Σ e⁽Yj⁾ : It applies the exponential function to each element and normalizes it by dividing by the sum of all these exponentials: Basically it squashes the output between 0 and 1.\n",
        "#    so we get probabilities => The sum of the outputs is equal to 1  \n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "def softmax(x):\n",
        "  return np.exp(x) / np.sum(np.exp(x),axis=0)\n",
        "\n",
        "x=np.array([2.0,1.0,0.1])\n",
        "outputs=softmax(x)\n",
        "print('softmax numpy',outputs)\n",
        "\n",
        "#We can also calculate it using pytorch\n",
        "x1=torch.tensor([2.0,1.0,0.1])\n",
        "outputs=torch.softmax(x1,dim=0) #We should specify the dimension==0, So it computes it along the first axis\n",
        "print(\"Softmax torch\",outputs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ApUOan8H9GYV",
        "outputId": "bd57dfd4-5626-4857-9d13-101197244a7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "softmax numpy [0.65900114 0.24243297 0.09856589]\n",
            "Softmax torch tensor([0.6590, 0.2424, 0.0986])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#A lot of times, the softmax function is combined with the so-called cross-entropy loss.. So this measures the performance of our classification model whose output is a probability between 0 and 1.\n",
        "#And it can be used in multi-class problems, and the loss increases as the predicted probability diverges from the actual label. So the better our prediction, the lower our loss.\n",
        "#But we should pay attention here; Our Y must be One-Hot encodded class labels\n",
        "####Let's see how we can do this in numpy:\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "def cross_entropy(actual,predicted):\n",
        "  loss=-np.sum(actual*np.log(predicted))\n",
        "  return loss # We can also normalize it, but we will not do this here: /float(predicted.shape[0]) : By dividing it by the number of samples\n",
        "\n",
        "#y must be one hot encoded\n",
        "#If class 0: [1 0 0]\n",
        "#If class 1: [0 1 0]\n",
        "#If class 2: [0 0 1]\n",
        "Y=np.array([1,0,0])\n",
        "\n",
        "#Y_pred has probabilities\n",
        "Y_pred_good = np.array([0.7,0.2,0.1])\n",
        "Y_pred_bad = np.array([0.1,0.3,0.6])\n",
        "l1=cross_entropy(Y,Y_pred_good)\n",
        "l2=cross_entropy(Y,Y_pred_bad)\n",
        "\n",
        "print(f'The loss for the good prediction is {l1:.4f}')\n",
        "print(f'The loss for the bad prediction is {l2:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o8aKIEaorn-K",
        "outputId": "09354eb8-d204-45b2-96cb-413956961575"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The loss for the good prediction is 0.3567\n",
            "The loss for the bad prediction is 2.3026\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Now let's see how we can do this using pytorch\n",
        "loss= nn.CrossEntropyLoss()\n",
        "'''Be Careful!\n",
        "nn.CrossEntroyLoss applies\n",
        "nn.LogSoftmax + nn.NLLLoss (negative log likelihood loss)\n",
        "--> No softmax in last layer!\n",
        "Y has class labels, not One-Hot!\n",
        "Y_pred has raw scores(logits), no softmax!\n",
        "\n",
        "Now Let's see this in practice:'''\n",
        "#Let's set our labels:\n",
        "Y=torch.tensor([0]) #Here we only put the correct class label: The class 0 is the correct answer.\n",
        "#We must be careful about the size; This has the size nsamples*nclasses: In our case nsamples=1*nclasses=3\n",
        "Y_pred_good=torch.tensor([[2.0,1.0,0.1]])  #This is an array of arrays.. And remeber; this are the raw values; We didn't apply the softmax, and here, the class 0 has the highest value; So this is a good prediction\n",
        "Y_pred_bad=torch.tensor([[0.1,4.0,2.0]])\n",
        "\n",
        "l1=loss(Y_pred_good,Y)\n",
        "l2=loss(Y_pred_bad,Y)\n",
        "print(\"l1=\",l1)\n",
        "print(\"l1=\",l1.item())\n",
        "print(\"l2\",l2)\n",
        "print(\"l2=\",l2.item())\n",
        "\n",
        "#Now to get the actual predictions:\n",
        "_,prediction1=torch.max(Y_pred_good,1) #Why 1? Along the 1st dimension\n",
        "_,prediction2=torch.max(Y_pred_bad,1) \n",
        "#--> prediction1 and prediction2 get the indices of the maximum; That's why we did _,prediction1\n",
        "print(f'prediction1:{prediction1}')\n",
        "print(f'prediction2:{prediction2}')\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "And to understand more:\n",
        " k=torch.tensor([[4,9,2]])\n",
        " print(torch.max(k,1))\n",
        "\n",
        "#Then we got:\n",
        "torch.return_types.max(\n",
        "values=tensor([9]),\n",
        "indices=tensor([1]))\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "k5kKFaoC3KFR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#What's also very good is that the loss in pytorch allows for a multiple samples.. So let's increase our samples here.\n",
        "\n",
        "#Now we have 3 samples with 3 classes for each.\n",
        "Y=torch.tensor([2,0,1])\n",
        "#We must be careful about the size of the prediction; This has the size nsamples*nclasses: In our case nsamples=3*nclasses=3\n",
        "Y_pred_good=torch.tensor([[0.4,1.0,2.0],[2.0,1.0,0.5],[0.1,2,0.1]])\n",
        "Y_pred_bad=torch.tensor([[0.1,2,0.1],[0.4,1.0,2.0],[2.0,1.0,0.5]])\n",
        "#And then we can compute again the cross-entropy loss with multpile samples\n",
        "l1=loss(Y_pred_good,Y)\n",
        "l2=loss(Y_pred_bad,Y)\n",
        "print(\"l2\",l1) #The loss overall\n",
        "print(\"l2=\",l2) #The loss overall\n",
        "\n",
        "#Now to get the actual predictions:\n",
        "_,prediction1=torch.max(Y_pred_good,1) #Why 1? Along the 1st dimension\n",
        "_,prediction2=torch.max(Y_pred_bad,1) \n",
        "#--> prediction1 and prediction2 get the indices of the maximum; That's why we did _,prediction1\n",
        "print(f'prediction1:{prediction1}')\n",
        "print(f'prediction2:{prediction2}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MwF-5iQi4y5c",
        "outputId": "62411632-911d-47e4-a89b-57caffb7fee9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "l2 tensor(0.3923)\n",
            "l2= tensor(1.8923)\n",
            "prediction1:tensor([2, 0, 1])\n",
            "prediction2:tensor([1, 2, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Now we are going to see how a typical neural network looks like; For instance; a multi-class classification\n",
        "\n",
        "#Binary  classification:\n",
        "class NeuralNet(nn.Module):\n",
        "  def __init__(self,input_size,hidden_size, num_classes):\n",
        "    super(NeuralNet,self).__init__()\n",
        "    self.linear1=nn.linear(input_size,hidden_size)\n",
        "    self.relu=nn.ReLU()\n",
        "    self.linear2=nn.linear(hidden_size,num_classes)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    out=self.linear1(x)\n",
        "    out=self.relu(out)\n",
        "    out=self.linear2(out)\n",
        "    #no softmax at the end\n",
        "    return out\n",
        "MyModel=NeuralNet(input_size=28*28,hidden_size=5,num_classes=3)\n",
        "criterion=nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "#If it's a case of binary classification:\n",
        "#We can have num_classes=1, and then apply a sigmoid function; It returns a probability; and then for example say if >0.5, then Yes, else NO.\n",
        "#In pyTorch: Use nn.BCELoss() which is Binary Cross Entropy.\n",
        "#ALSO DON'T FORGET: SIGMOID AT THE END!\n"
      ],
      "metadata": {
        "id": "4YdfNIkxEg9G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Now let's have a look at our neural net in a binary classification case:\n",
        "\n",
        "#Binary classification:\n",
        "class NeuralNet(nn.Module):\n",
        "  def __init__(self,input_size,hidden_size):\n",
        "    super(NeuralNet,self).__init__()\n",
        "    self.linear1=nn.linear(input_size,hidden_size)\n",
        "    self.relu=nn.ReLU()\n",
        "    self.linear2=nn.linear(hidden_size,1)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    out=self.linear1(x)\n",
        "    out=self.relu(out)\n",
        "    out=self.linear2(out)\n",
        "    #Sigmoid at the end\n",
        "    y_pred=torch.sigmoid(out)\n",
        "    return y_pred\n",
        "\n",
        "MyModel=NeuralNet(input_size=28*28,hidden_size=5)\n",
        "criterion=nn.BCELoss()\n"
      ],
      "metadata": {
        "id": "dBRynQssnsML"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#The last structure is also what we used in the logistic regression part. You can check that out..."
      ],
      "metadata": {
        "id": "v-OIOxWAosg5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Activation functions**"
      ],
      "metadata": {
        "id": "7ZwnXi7Go-VK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Activation functions apply a non-linear transformation and decide wether a neron should be activated or not\n",
        "#Why to use activation functions? Without activation functions our network is basically just a stacked linear regression model( regression*regression*regression)\n",
        "#With non-linear transformations, our network can learn better and perform more complex tasks!\n",
        "#After each layer, we typically use an activation function.\n",
        "#Most popular activation functions are: 1)Step function 2)Sigmoid 3)TanH 4)ReLU 5)Leaky ReLU 6) Softmax\n",
        "#1)Step function: Not used in practice\n",
        "#2)Sigmoid: Typically in the last layer of a binary classification problem\n",
        "#3)TanH: Hidden layers\n",
        "#4)ReLU: If you don't know what to use, just use a ReLU for hidden layers\n",
        "#5)Leaky ReLU: Improved version of ReLU. Tries to solve the vanishing gradient problem, because with a normal ReLU, our values in the negative part are zero; This means that also the gradient later in \n",
        "#              the backpropagation is zero, and when the gradient is zero, then this means that these weights will never be updated. So these neurons won't learn anything==The neurons are dead.\n",
        "#              So, whanever you notice that your weights won't update\n",
        "#6)Softmax: Good in the last layer in multi-class classification problems.\n",
        "\n",
        "\n",
        "#And now, let's jump to the code, and see how we can use them in pytorch\n",
        "#So, we have 2 options; Option1: Create nn modules. Option2: Use activation functions directly in forward pass\n",
        "\n",
        "##############Option1 (Create nn modules)\n",
        "#For instance:\n",
        "#Binary classification:\n",
        "class NeuralNet(nn.Module):\n",
        "  def __init__(self,input_size,hidden_size):\n",
        "    super(NeuralNet,self).__init__()\n",
        "    self.linear1=nn.linear(input_size,hidden_size)\n",
        "    self.relu=nn.ReLU() ########################## We create our ReLU module here, and we can get that from the torch.nn module\n",
        "    self.linear2=nn.linear(hidden_size,1)\n",
        "    self.sigmoid=nn.Sigmoid()\n",
        "      \n",
        "  def forward(self, x):\n",
        "    out=self.linear1(x)\n",
        "    out=self.relu(out)\n",
        "    out=self.linear2(out)\n",
        "    #Sigmoid at the end\n",
        "    out=self.sigmoid(out)\n",
        "    return out\n",
        "\n",
        "\n",
        " ############Option2 (Use activation functions directly in forward pass)\n",
        " class NeuralNet(nn.module):\n",
        "   def __init__(self,input_size,hidden_size):\n",
        "     super(NeuralNet,self).__init__()\n",
        "     self.linear1=nn.linear(input_size,hidden_size)\n",
        "     self.linear2=nn.linear(hidden_size,1)\n",
        "  def forward(self,x):\n",
        "    out=torch.relu(self.linear1(x)) ################### We are using the torch.sigmoid function directly; This is just from the torch API.a\n",
        "    out=torch.sigmoid(self.linear2(out)) \n",
        "    return out\n",
        "'''So either torch.nn.Sigmoid, or torch.sigmoid'''\n",
        "\n",
        "#####Remark: Sometimes, there's some activation functions that are not available with torch API directly(option2), but they are available in torch.nn.functional: So import torch.nn.functional as F.\n",
        "#           For example, torch.nn.functional.leaky_relu() is only available this way... Also, as we have been saying, F.relu is just the same as torch.relu\n",
        "\n"
      ],
      "metadata": {
        "id": "3CKptjPbpBIi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Feed-Forward Neural Net**"
      ],
      "metadata": {
        "id": "PT0Phxhs99Q2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#MNIST\n",
        "#Dataloader, Transformation\n",
        "#Multilayer neural net, activation function\n",
        "#Loss and optimizer\n",
        "#Training loop (batch training)\n",
        "#Model evaluation\n",
        "#GPU support\n",
        "\n",
        "#Today, we are going to implement our first multi-layer neural network that can do digit classification based on the the famous MNIST dataset.\n",
        "#In this part, we are going to put all the things from the last sections together; So, we use the dataloader to load our dataset, we apply a transform to the dataset. Then we will implement our neural net\n",
        "#with input layer, hidden layer, and output layer. And we will, also, apply activation functions. Then, we set up the loss and optimizer, and implement the training loop that can use batch training.\n",
        "#And finally we evaluate our model and calculate the accuracy, and additionally, we will make sure that our whole code can also run on the GPU if we have GPU support."
      ],
      "metadata": {
        "id": "KPRyffX2-IxU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision #for the dataset\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt #To show you some data later\n",
        "\n",
        "#device configuration\n",
        "if torch.cuda.is_available():\n",
        "  print(\"Cuda is available\")\n",
        "  device=torch.device(\"cuda\")\n",
        "else:\n",
        "  device=torch.device(\"cpu\")\n",
        "\n",
        "#Hyper parameters\n",
        "input_size= 784 #which is 28by28; So we are flattening this array to be 1D tensor.\n",
        "hidden_size = 100\n",
        "num_classes = 10 #Since we have 10 different classes\n",
        "num_epochs = 2\n",
        "batch_size =100\n",
        "learning_rate = 0.001\n",
        "\n",
        "#Dataset: MNIST\n",
        "train_dataset =torchvision.datasets.MNIST(root='./data/', train=True,transform=transforms.ToTensor(),download=True)\n",
        "test_dataset =torchvision.datasets.MNIST(root='./data/', train=False,transform=transforms.ToTensor()) #We don't need it to download anymore.\n",
        "#root==where it has to be stored\n",
        "#So now, let's continue and create the dataloader:\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,batch_size=batch_size,shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,batch_size=batch_size,shuffle=False) #Here shuffle is false because it doesn't matter for the evaluation.\n",
        "#And now, let's have a look at one batch of this data:\n",
        "examples=iter(train_loader) #we convert it to an iter object\n",
        "samples, labels=examples.next()        #here we called the \"Next\" method\n",
        "print(f'the size of samples equals: {samples.shape} and the size of labels equals {labels.shape}') #100 because our batch_size is 100, so we have 100 samples in our batch,\n",
        "#and for the number of channels.. For the labels, we have: size of labels equals torch.Size([100]): For each class label, we have one value.\n",
        "\n",
        "#An iterator is an object that contains a countable number of values.\n",
        "#An iterator is an object that can be iterated upon, meaning that you can traverse through all the values.\n",
        "#Technically, in Python, an iterator is an object which implements the iterator protocol, which consist of the methods __iter__() and __next__().\n",
        "\n",
        "#Example: \n",
        "#mytuple = (\"apple\", \"banana\", \"cherry\")\n",
        "#myit = iter(mytuple)\n",
        "\n",
        "#print(next(myit))\n",
        "#print(next(myit))\n",
        "#print(next(myit))\n",
        "#>>apple\n",
        "#>>banana\n",
        "#>>cherry\n",
        "\n",
        "#Let's plot something:\n",
        "for i in range(6):\n",
        "  plt.subplot(2,3,i+1)\n",
        "  plt.imshow(samples[i][0],cmap='gray') #why [0]? because we want to access the first channel$\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "id": "zFc6nOrkFHkU",
        "outputId": "95fcd1da-7551-42ef-f6c8-1a3742bcfde9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cuda is available\n",
            "the size of samples equals: torch.Size([100, 1, 28, 28]) and the size of labels equals torch.Size([100])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 6 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#And now we want to classify these digits. For this, we want to setup a fully connected neural network with one hidden layer.\n",
        "class NeuralNet(nn.Module):\n",
        "  def __init__(self,input_size,hidden_size,num_classes):\n",
        "    super(NeuralNet,self).__init__()\n",
        "    self.l1=nn.Linear(input_size,hidden_size)\n",
        "    self.relu=nn.ReLU()\n",
        "    self.l2=nn.Linear(hidden_size,num_classes)\n",
        "  \n",
        "  def forward(self,x):\n",
        "    out=self.l1(x)\n",
        "    out=self.relu(out)\n",
        "    out=self.l2(out)\n",
        "    #Be careful!! Not to apply a softmax activation function here as usual in multiclass classification problems, because in a second we will see that we are going to use \n",
        "    #crossentropy loss, and this will apply the softmax for us.\n",
        "    return out\n",
        "    #So this is our whole model.\n",
        "    \n",
        "model=NeuralNet(input_size,hidden_size,num_classes)\n",
        "\n",
        "#Loss and optimizer\n",
        "criterion=nn.CrossEntropyLoss() #And as we have said, this will apply the softmax for us\n",
        "optimizer=torch.optim.Adam(model.parameters(),lr=learning_rate)\n",
        "\n",
        "\n",
        "#Training loop\n",
        "#First let's define the number of total steps, and this is the length of the training loader.\n",
        "n_total_steps=len(train_loader) #OF COURSE MAN(We don't devide by batch size, because every item in data_loader represents a one singel batch; which is in our case equal to 100)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  #Now we loop over all the batches\n",
        "  for i, (images,labels) in enumerate(train_loader):\n",
        "    #The enumerate function will give us the actual index, and the data; which is a tuple of the images and the labels\n",
        "\n",
        "    #First, we have to reshape our images, because if we have a look at the shape, then we see that this is [100,1,28,28]\n",
        "    #And now we set our input size as  #784, so our images tensor needs the size [100,784]\n",
        "\n",
        "    images=images.reshape(-1,28*28).to(device) \n",
        "    labels=labels.to(device)\n",
        "\n",
        "    #Forward pass\n",
        "    outputs=model(images)\n",
        "  \n",
        "    loss= criterion(outputs,labels) #This will get the predicted outputs and the actual labels\n",
        "\n",
        "    #Backward pass\n",
        "    optimizer.zero_grad() #To empty the values in the gradient attribute\n",
        "    loss.backward() #This will do the back propagation\n",
        "    optimizer.step() #This will do an update step and update the parameters for us\n",
        "\n",
        "\n",
        "    if (i+1) % 100 ==0:\n",
        "      print(f'epoch {epoch+1} / {num_epochs}, step {i+1} / {n_total_steps}, loss={loss.item():.4f}')\n",
        "\n",
        "##Test and evaluation\n",
        "#For this we don't want to compute the gradients for all the steps we do. So we want to wrap this in a with torch.no_grad()\n",
        "with torch.no_grad():\n",
        "  n_correct=0 #The number of correct predictions\n",
        "  n_samples=0\n",
        "  #And then we loop over all the batches in the test samples\n",
        "  for images,labels in test_loader:\n",
        "    images=images.reshape(-1,28*28).to(device)\n",
        "    labels=labels.to(device)\n",
        "    outputs= model(images) ##This is our trained model now; The model.parameters() in the optimizer are its..\n",
        "    #Then, let's get the actual predictions\n",
        "    #Now to get the actual predictions:\n",
        "    _,predictions=torch.max(outputs,1) #Why 1? Along the 1st dimension .. The torch.max function will return the value and the index.. So we are interested in the actual index\n",
        "    #So this is the class label\n",
        "    n_samples+=labels.shape[0] #So this will give us the number of samples in the current batch.. so should be 100.\n",
        "    n_correct+=(predictions== labels).sum().item() #For each correct prediction, we will add 1\n",
        "  #And then when we are done with the loop, we calculate the total accuracy by saying:\n",
        "  acc=100.0*(n_correct/n_samples)\n",
        "  print(f'accuracy={acc}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_rG9sMhxOEup",
        "outputId": "e3ae0f07-5035-4c78-9729-1a3a9a556841"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1 / 2, step 100 / 600, loss=0.4855\n",
            "epoch 1 / 2, step 200 / 600, loss=0.2752\n",
            "epoch 1 / 2, step 300 / 600, loss=0.2584\n",
            "epoch 1 / 2, step 400 / 600, loss=0.3462\n",
            "epoch 1 / 2, step 500 / 600, loss=0.2945\n",
            "epoch 1 / 2, step 600 / 600, loss=0.2588\n",
            "epoch 2 / 2, step 100 / 600, loss=0.2329\n",
            "epoch 2 / 2, step 200 / 600, loss=0.1848\n",
            "epoch 2 / 2, step 300 / 600, loss=0.0882\n",
            "epoch 2 / 2, step 400 / 600, loss=0.1684\n",
            "epoch 2 / 2, step 500 / 600, loss=0.1501\n",
            "epoch 2 / 2, step 600 / 600, loss=0.1718\n",
            "accuracy=95.36\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **CNN**"
      ],
      "metadata": {
        "id": "JHsQhXNL2wvN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#In this part we are going to implement a convolutional neural network and do image classification based on the CIFAR-10 dataset; it consists of 60000 32x32 colour images in 10 classes, and it's directly \n",
        "#available in pytorch.\n",
        "#So; conv nets are similar to ordinary neural nets; They are made up of neurons that have learnable weights and biases. And the main difference now  is that conv nets mainly work on image data, and apply\n",
        "#the so-called convolutional filters; So a typical conv net architecture looks like \"/home/nour/Desktop/_NextAV/_2022/_AI course/CNN.png\": CONV-RELU-COV-RELU -POOL- CONV-RELU-CONV-RELU -POOL- CONV-RELU-CONV-RELU -POOL- FC\n",
        "#We have different convolutional layers, and optional activation functions followed by so-called pooling layers, and these layers are used to automatically learn some features from the image..and then at the end,\n",
        "#we have one or more fully connected layers for the actual classification task. So, this is a typical architecture of a CNN, and these convolutional filters they work by applying a filter kernel to our image, \n",
        "#And the size of the resulting image will be less than the initial image unless we do padding.\n",
        "#Remark: Max pooling ins used to reduce the computational cost by reducing the size of the image; This reduces the number of parameters that our model has to learn. And it also helps to avoid overfitting,\n",
        "#by providing an abstarcted form of the input"
      ],
      "metadata": {
        "id": "awn7Q03O2ykv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F \n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "#Device configuration\n",
        "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "#Hyper-parameters\n",
        "num_epochs=4\n",
        "batch_size=4\n",
        "learning_rate=0.001\n",
        "\n",
        "#Dataset has PILImage images of range [0,1]\n",
        "#We transfom them to Tensors of normalized range [-1,1]\n",
        "transform=transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))]\n",
        "     )\n",
        "train_dataset=torchvision.datasets.CIFAR10(root='./data',train=True, download=True,transform=transform)\n",
        "test_dataset=torchvision.datasets.CIFAR10(root='./data',train=False, download=True,transform=transform)\n",
        "train_loader=torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader=torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "classes= ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "#Implement conv net\n",
        "class convNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(convNet,self).__init__()\n",
        "    self.conv1=nn.Conv2d(3,6,5) #Here we have to specify the sizes; the input_channel_sizes=3 because our images have three color channels.. and the output_channel_size is 6, and the kernel size is five(5x5)\n",
        "    self.pool=nn.MaxPool2d(2,2) #With kernel_size=2, and a stride of 2(After each operation we shift 2 pixels to the right) #Pooling will be used twice.\n",
        "    self.conv2=nn.Conv2d(6,16,5)\n",
        "    #So now we have our convolutional layers, and now let' set up the fully connected layer\n",
        "    self.fc1 = nn.Linear(16*5*5,120) #######Why is that like this? We can change 120 and 84, but (16x5x5) and 10 should be fixed. But why (16x5x5)? well we have as input layer [4,3,32,32].. After the first conv,\n",
        "    #it's [4,6,28,28], after pool it's [4,6,14,14],after the second convolution layer; it's [4,16,12,10].. then we apply another pooling; so the final size is [4,16,5,5]: 16 layer/ 5x5 images.\n",
        "    #So now, after these convolutional layers, when we put them into our classification layers, we want to flatten the size, so we want to flatten our 3D tensor to a 1D tensor.\n",
        "    self.fc2=nn.Linear(120,84)\n",
        "    self.fc3=nn.Linear(84,10)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def forward(self,x):\n",
        "    #So now we have the correct sizes; so we have all the layers defined, and now we have to apply them in the forward pass.4\n",
        "    x=self.pool(F.relu(self.conv1(x))) #Of course the activation function does not change the size\n",
        "    #Then we do the same thing with the second convolutional layer.\n",
        "    x=self.pool(F.relu(self.conv2(x)))\n",
        "    #And now, we have to pass it to the first fully connected layer, and for this, we have to flatten it.\n",
        "    x=x.view(-1,16*5*5) #The first size we can simply say -1; So pytorch can automatically define the correct size for us; So (-1) is the number of batches; The number of samples we have in our batch here: So 4 in this case\n",
        "    #Now we have our tensor flattened\n",
        "    x=F.relu(self.fc1(x))\n",
        "    x=F.relu(self.fc2(x))\n",
        "    x=self.fc3(x)\n",
        "    #And no activation function at the end; and no softmax either; since it's already included in our loss\n",
        "    return x\n",
        "\n",
        "\n",
        "model=convNet().to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate)\n",
        "\n",
        "n_total_steps=len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "  for i, (images,labels) in enumerate(train_loader):\n",
        "    #origin shape: [4,3,32,32]=4,3,1024\n",
        "    #input_layer: 3 input channels, 6 output channels, 5 kernel size\n",
        "    images=images.to(device)\n",
        "    labels=labels.to(device)\n",
        "\n",
        "    #Forward pass\n",
        "    outputs=model(images)\n",
        "    loss=criterion(outputs,labels)\n",
        "\n",
        "\n",
        "    #Backward and optimize\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if(i+1) % 2000==0:\n",
        "      print(f'Epoch [{epoch+1}/{num_epochs}],Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n",
        "\n",
        "print('Finished Training') \n",
        "\n",
        "with torch.no_grad():\n",
        "  n_correct = 0\n",
        "  n_samples = 0\n",
        "  n_class_correct = [0 for i in range(10)]\n",
        "  n_class_samples = [0 for i in range(10)]\n",
        "  for images, labels in test_loader:\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "    outputs = model(images)\n",
        "    #max returns (value,index)\n",
        "    _,predicted = torch.max(outputs,1)\n",
        "    n_samples+=labels.size(0)\n",
        "    n_correct+=(predicted==labels).sum().item()\n",
        "\n",
        "    for i in range(batch_size):\n",
        "      label = labels[i]\n",
        "      pred = predicted[i]\n",
        "      if (label==pred):\n",
        "        n_class_correct[label]+=1\n",
        "      n_class_samples[label]+=1\n",
        "  acc=100.0* n_correct /n_samples\n",
        "  print(f'Accracy of the network: {acc}%')\n",
        "\n",
        "  for i in range(10):\n",
        "    acc = 100.0 * n_class_correct[i] / n_class_samples[i]\n",
        "    print(f'Accuracy of {classes[i]}:{acc}%')\n",
        "#The accuracy is not at that good, since this is just a test: for instance we trained just for 4 epochsb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgYMcLpm4ebF",
        "outputId": "ac16efa2-a624-4eaf-8691-ee246f3e45de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Epoch [1/4],Step [2000/12500], Loss: 2.2801\n",
            "Epoch [1/4],Step [4000/12500], Loss: 2.3110\n",
            "Epoch [1/4],Step [6000/12500], Loss: 2.2909\n",
            "Epoch [1/4],Step [8000/12500], Loss: 2.3115\n",
            "Epoch [1/4],Step [10000/12500], Loss: 2.2892\n",
            "Epoch [1/4],Step [12000/12500], Loss: 2.2961\n",
            "Epoch [2/4],Step [2000/12500], Loss: 2.2926\n",
            "Epoch [2/4],Step [4000/12500], Loss: 2.3207\n",
            "Epoch [2/4],Step [6000/12500], Loss: 2.3379\n",
            "Epoch [2/4],Step [8000/12500], Loss: 1.9387\n",
            "Epoch [2/4],Step [10000/12500], Loss: 2.1477\n",
            "Epoch [2/4],Step [12000/12500], Loss: 1.9570\n",
            "Epoch [3/4],Step [2000/12500], Loss: 1.9758\n",
            "Epoch [3/4],Step [4000/12500], Loss: 1.0404\n",
            "Epoch [3/4],Step [6000/12500], Loss: 1.9084\n",
            "Epoch [3/4],Step [8000/12500], Loss: 1.5731\n",
            "Epoch [3/4],Step [10000/12500], Loss: 1.6099\n",
            "Epoch [3/4],Step [12000/12500], Loss: 1.2970\n",
            "Epoch [4/4],Step [2000/12500], Loss: 1.9955\n",
            "Epoch [4/4],Step [4000/12500], Loss: 1.3933\n",
            "Epoch [4/4],Step [6000/12500], Loss: 1.0973\n",
            "Epoch [4/4],Step [8000/12500], Loss: 1.4496\n",
            "Epoch [4/4],Step [10000/12500], Loss: 1.4042\n",
            "Epoch [4/4],Step [12000/12500], Loss: 1.0976\n",
            "Finished Training\n",
            "Accracy of the network: 44.67%\n",
            "Accuracy of plane:58.1%\n",
            "Accuracy of car:46.6%\n",
            "Accuracy of bird:22.7%\n",
            "Accuracy of cat:48.1%\n",
            "Accuracy of deer:32.8%\n",
            "Accuracy of dog:43.2%\n",
            "Accuracy of frog:37.2%\n",
            "Accuracy of horse:49.5%\n",
            "Accuracy of ship:53.9%\n",
            "Accuracy of truck:54.6%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Transfer learning**"
      ],
      "metadata": {
        "id": "SlINR4AlVyFZ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hQi2XrvKV2I9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}